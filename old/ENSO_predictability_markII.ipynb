{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of ENSO predictability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import doppyo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "# Notebook specific -----\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveloc = '/OSM/CBR/OA_DCFP/work/squ027/squire_scratch/projects/papers/Risbey_Nature/figures'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook-specific functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_anomalize = lambda data, clim: doppyo.utils.datetime_to_leadtime(\n",
    "                                          doppyo.utils.anomalize(\n",
    "                                              doppyo.utils.leadtime_to_datetime(data), clim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_keys(path):\n",
    "    basename = os.path.basename(path)\n",
    "    return [ int(c) for c in re.split('(\\d+)', basename) if c.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_anomalize(fcst, clim_ts, time_dim = 'init_date'):\n",
    "    \"\"\" Anomalize provided data in a \"cross-validated\" manner \"\"\"\n",
    "    \n",
    "    fcst_dates = fcst[time_dim].values\n",
    "    if not hasattr(fcst_dates, \"__iter__\"):\n",
    "        fcst_dates = [fcst_dates]\n",
    "    clim_dates = clim_ts[time_dim].values\n",
    "    if not hasattr(clim_dates, \"__iter__\"):\n",
    "        clim_dates = [clim_dates]\n",
    "        \n",
    "    clim = clim_ts.sel({time_dim : sorted(set(clim_dates) - set(fcst_dates))}) \\\n",
    "                  .groupby(time_dim+'.month').mean(time_dim)\n",
    "\n",
    "    return fcst - clim.sel(month = fcst[time_dim].dt.month.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Delsole_regression(da_predict,  da_train):\n",
    "    \"\"\" \n",
    "        Build model over dates in da_predict using data in da_train\n",
    "        Overlapping periods in da_predict and da_train are excluded from the training period\n",
    "    \"\"\"\n",
    "    \n",
    "    def _fit(da):\n",
    "        return doppyo.utils.polyfit(da.sel(lead_time=0), da.sel(lead_time=range(1,12)), order=1, over_dims='init_date')\n",
    "    \n",
    "    def _predict(da, p):\n",
    "        month = da.init_date.dt.month.values[0]\n",
    "        return doppyo.utils.polyval(da, p.sel(month=month, drop=True), over_dims='init_date')\n",
    "\n",
    "    if da_predict.shape == ():\n",
    "        da_predict = da_predict.expand_dims('init_date')\n",
    "    da_predict = doppyo.utils.prune(da_predict)\n",
    "\n",
    "    train_dates = da_train['init_date'].values\n",
    "    if not hasattr(train_dates, \"__iter__\"):\n",
    "        train_dates = [train_dates]\n",
    "    predict_dates = da_predict['init_date'].values\n",
    "    if not hasattr(predict_dates, \"__iter__\"):\n",
    "        predict_dates = [predict_dates]\n",
    "        \n",
    "    da_use = da_train.sel({'init_date' : sorted(set(train_dates) - set(predict_dates))})\n",
    "    \n",
    "    p = da_use.groupby('init_date.month').apply(_fit)\n",
    "    \n",
    "    if len(predict_dates) == 1:\n",
    "        return _predict(da_predict, p=p).squeeze()\n",
    "    else:\n",
    "        return da_predict.groupby('init_date.month', squeeze=True).apply(_predict, p=p).drop('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def where_elninos(da):\n",
    "    \n",
    "    s = np.array([[False,True,True],[True,True,True],[True,True,False]])\n",
    "    \n",
    "    where_elnino = da.rolling(init_date=3, center=True).mean() > 0.5\n",
    "    where_elnino.values = label(1*where_elnino, structure=s)[0]\n",
    "    \n",
    "    return where_elnino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def where_laninas(da):\n",
    "    \n",
    "    s = np.array([[False,True,True],[True,True,True],[True,True,False]])\n",
    "    \n",
    "    where_lanina = da.rolling(init_date=3, center=True).mean() < -0.5\n",
    "    where_lanina.values = label(1*where_lanina, structure=s)[0]\n",
    "    \n",
    "    return where_lanina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def where_condition_events(where_event, method):\n",
    "\n",
    "    for event_id in range(1, where_event.max().values+1):\n",
    "        specific_event = 1*(where_event == event_id)\n",
    "\n",
    "        if method == 'decay':\n",
    "            specific_event = -1 * (specific_event - 1)\n",
    "\n",
    "        int_event = doppyo.utils.integrate(specific_event, over_dim='lead_time', \n",
    "                                            x=(1+0*specific_event.lead_time.astype(int)).cumsum('lead_time'), \n",
    "                                            method='rect', cumulative=True)\n",
    "        int_cmpar = (1+0*specific_event.astype(int)).cumsum('lead_time')\n",
    "\n",
    "        specific_event_conditioned = specific_event.where(int_event != int_cmpar, other=0)\n",
    "        \n",
    "        if method == 'decay':\n",
    "            specific_event_conditioned = specific_event_conditioned.where(specific_event.sel(lead_time=0) == 0, other=0)\n",
    "            \n",
    "        if event_id == 1:\n",
    "            event_conditioned = specific_event_conditioned\n",
    "        else:\n",
    "            event_conditioned = event_conditioned + specific_event_conditioned\n",
    "            \n",
    "    return event_conditioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fcst(t, x, ax=None, cmap='jet', **kwargs):\n",
    "    # Convert dates to numbers first ---- \n",
    "    try:\n",
    "        inxval = matplotlib.dates.date2num(t.to_index().to_pydatetime())\n",
    "        points = np.array([inxval, x.values]).T.reshape(-1,1,2)\n",
    "    except:\n",
    "        inxval = matplotlib.dates.date2num(t)\n",
    "        points = np.array([inxval, x]).T.reshape(-1,1,2)\n",
    "    segments = np.concatenate([points[:-1],points[1:]], axis=1)\n",
    "    \n",
    "    lc = LineCollection(segments, cmap=cmap, **kwargs)\n",
    "    lc.set_array(inxval)\n",
    "    \n",
    "    monthFmt = matplotlib.dates.DateFormatter(\"%Y\")\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    ax.add_collection(lc)\n",
    "    ax.xaxis.set_major_formatter(monthFmt)\n",
    "    ax.autoscale_view()\n",
    "    ax.xaxis_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors1 = ['#8dd3c7','#ffffb3','#bebada','#fb8072','#80b1d3','#fdb462','#b3de69']\n",
    "colors2 = ['#e41a1c','#377eb8','#4daf4a','#984ea3','#ff7f00','#ffff33','#a65628']\n",
    "colors3 = ['#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f']\n",
    "colors4 = ['#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e','#e6ab02','#a6761d']\n",
    "colorsd = ['#1f77b4','#ff7f0e','#2ca02c','#d62728','#9467bd','#8c564b','#e377c2']\n",
    "colors = colorsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A note about climatologies and bias corrections\n",
    "The CMC Can3/4 hindcasts / forecasts span the periods 1981-01 -> 2010-12 / 2011-01 -> 2018-09. The GFDL and COLA models span 1982-01 -> 2018-11. The Hadley ISST data spans 1870-01 -> 2018-02.\n",
    "The mutual span of these datasets is **1982-01 -> 2018-02**\n",
    "\n",
    "In this notebook we compare and contrast a number of methods for computing anomalies and for bias correcting data. In all cases, **17 years of data are use to build climatologies**. The methods are abbreviated as follows:\n",
    "\n",
    "**c0** : model anomalies over the period **1999-01 -> 2015-12** are computed relative to the observed climatology over the period **1982-01 -> 1998-12** - see Saha et al. (2006), Kirtman (2003), Kirtman et al. (1997), Kirtman and Min (2009)... Observed anomalies are computed in the same way.\n",
    "\n",
    "**c1** : model anomalies over the period **1999-01 -> 2015-12** are computed relative to the (lead-time-dependent) ensemble mean model climatology over the same period using cross-validation - see Kirtman and Min (2009), Kirtman *et al.* (2014)... Similarly, observed anomalies over the period **1999-01 -> 2015-12** are computed relative to the observed climatology over the same period using cross-validation\n",
    "\n",
    "**c2** : model anomalies over the period **1999-01 -> 2015-12** are computed relative to the (lead-time-dependent) ensemble mean model climatology over the period **1982-01 -> 1998-12**. Similarly, observed anomalies over the period **1999-01 -> 2015-12** are computed relative to the observed climatology over the period **1982-01 -> 1998-12**\n",
    "\n",
    "**c3** : as in Delsole and Tippet, the (lead-time-dependent) mean forecast error for each calendar month using hindcasts whose verifications lie within the period 1982â€“98 inclusive. This error is then subtracted from the **c0** anomalies. This approach is subtly different from **c2** - if instead, the mean error were computed as the difference between the lead-time-dependent model climatology and the observed climatology over the period 1982-1998, then **c3** -> **c2**. Observed anomalies are the same as for **c2**.\n",
    "\n",
    "**Note**, in actuality model anomalies are computed over the full model period, but they should only be examined for **1999-01 -> 2015-12**\n",
    "\n",
    "For comparison, we also compute:\n",
    "\n",
    "**c1full** : model anomalies over the period **1982-01 -> 2015-12** are computed relative to the ensemble mean, lead=0 model climatology over the same period using cross-validation - see Kirtman and Min (2009), Kirtman *et al.* (2014)... Similarly, observed anomalies over the period **1982-01 -> 2015-12** are computed relative to the observed climatology over the same period using cross-validation\n",
    "\n",
    "**c1ncv** : model anomalies over the period **1982-01 -> 2015-12** are computed relative to the ensemble mean, lead=0 model climatology over the same period **without cross-validation**. Similarly, observed anomalies over the period **1982-01 -> 2015-12** are computed relative to the observed climatology over the same period **without cross-validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_data = False # If True, recomputes quantities from raw data and saves to dataloc, otherwise loads from dataloc\n",
    "dataloc = '/OSM/CBR/OA_DCFP/work/squ027/intermediate_products/tmp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw NOAA OISST data (downloaded from http://www.cpc.ncep.noaa.gov/data/indices/sstoi.indices.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = pd.date_range(start='1982-01',end='2019-02',freq='MS')\n",
    "data = np.array([26.72,26.7,27.2,28.02,28.54,28.75,28.1,27.93,28.11,28.64,28.81,29.21,29.36,29.13,29.03,28.91,28.89,28.24,27.07,26.53,26.44,25.87,25.58,25.59,25.64,26.39,26.86,27.39,27.39,26.86,26.74,26.34,26.43,25.93,25.41,25,25.43,25.67,26.23,26.8,27.11,26.86,26.69,26.5,26.25,26.19,26.19,26.11,25.79,25.94,26.65,27.44,27.5,27.69,27.37,27.15,27.33,27.57,27.73,27.7,27.91,28.02,28.47,28.8,28.75,29.03,28.8,28.58,28.39,28.07,27.99,27.6,27.32,27.22,27.31,27.32,26.48,26.11,25.57,25.24,25.43,24.62,24.27,24.33,24.53,25.33,25.9,26.69,27.09,26.98,26.74,26.33,26.25,26.26,26.24,26.38,26.55,26.95,27.46,28.02,28.06,27.58,27.25,27.05,26.75,26.98,26.72,26.91,27.01,26.93,27.25,27.98,28.35,28.36,27.92,27.44,27.07,27.63,27.86,28.37,28.41,28.63,28.83,29.14,28.99,28.02,27.53,26.64,26.48,26.34,26.51,26.73,26.69,26.97,27.66,28.59,28.82,28.28,27.55,26.84,26.92,26.93,26.91,26.76,26.6,26.59,27.27,27.9,28.04,27.99,27.35,27.35,27,27.49,27.87,27.87,27.55,27.45,27.63,27.93,27.73,27.59,27.01,26.33,25.96,25.67,25.66,25.57,25.74,25.85,26.62,27.36,27.37,27.32,27.09,26.56,26.35,26.24,26.19,26.02,25.96,26.36,27.03,28.03,28.6,28.94,28.92,28.84,28.93,29.23,29.32,29.26,29.1,28.86,28.67,28.56,28.47,26.72,25.94,25.49,25.61,25.34,25.18,24.79,24.9,25.41,26.25,26.84,26.97,26.6,26.35,25.59,25.71,25.64,25.12,24.9,24.65,25.19,26.08,27.01,27.12,27.03,26.72,26.45,26.21,25.96,25.78,25.59,25.74,26.11,26.84,27.52,27.6,27.68,27.32,26.87,26.55,26.59,26.45,26.17,26.5,26.95,27.32,27.94,28.15,28.43,27.98,27.79,27.83,28.05,28.27,28.09,27.76,27.49,27.81,27.81,27.37,27.48,27.43,26.85,26.96,27.19,27.05,26.89,26.74,26.86,27.1,27.84,28.06,27.76,27.69,27.54,27.47,27.38,27.31,27.31,27.1,26.96,27.55,28.07,28.2,28.05,27.47,26.88,26.63,26.75,26.34,25.89,25.64,26.08,26.57,27.59,27.91,27.85,27.35,27.22,27.34,27.47,27.73,27.76,27.26,26.81,27.18,27.78,27.57,27.55,26.79,26.2,25.77,25.22,25.06,24.97,24.71,24.83,26.07,26.83,27.18,27.17,27.19,26.85,26.44,26.33,26.3,25.74,25.54,26.04,26.67,27.5,28.03,28.11,27.94,27.53,27.47,27.63,28.19,28.3,28.07,27.94,28.29,28.36,27.68,27,26.09,25.5,25.07,25.01,25.07,24.95,24.93,25.46,26.23,27.02,27.42,27.46,26.96,26.19,25.98,25.72,25.6,25.53,25.49,26.03,26.63,27.38,27.8,27.95,27.75,27.55,27.24,26.98,27.01,26.46,26.16,26.32,27,27.68,27.57,27.43,26.91,26.54,26.65,26.36,26.65,26.53,26.06,26.18,26.99,28.01,28.31,28.11,27.4,27.02,27.17,27.17,27.5,27.35,27.1,27.29,27.79,28.56,28.88,28.96,28.82,28.89,29,29.15,29.6,29.39,29.17,29.12,28.9,28.87,28.15,27.53,26.73,26.28,26.11,25.96,26.1,26.16,26.25,26.87,27.34,28.1,28.3,28.19,27.61,26.67,26.29,26.23,25.79,25.8,25.82,25.83,26.48,27.42,27.72,27.85,27.52,27.11,27.1,27.55,27.64,27.53,27.08,27.38])\n",
    "\n",
    "oisst_nino34_full_ts = xr.DataArray(data, coords=[('time', time)])\n",
    "oisst_nino34_full = doppyo.utils.stack_by_init_date(oisst_nino34_full_ts, init_dates=pd.date_range('1982-01','2015-12',freq='MS'), N_lead_steps=12).rename('full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c0 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno -51] NetCDF: Unknown file format: b'/OSM/CBR/OA_DCFP/work/squ027/intermediate_products/tmp/ENSO_predictability.oisst_nino34_c0.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-72712afd4ba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moisst_nino34_c0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_netcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'ENSO_predictability.oisst_nino34_c0.nc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moisst_nino34_c0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'ENSO_predictability.oisst_nino34_c0.nc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'c0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, group, decode_cf, mask_and_scale, decode_times, autoclose, concat_characters, decode_coords, engine, chunks, lock, cache, drop_variables, backend_kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m                                                    \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                                                    \u001b[0mautoclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                                                    **backend_kwargs)\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'scipy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             store = backends.ScipyDataStore(filename_or_obj,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, filename, mode, format, group, writer, clobber, diskless, persist, autoclose, lock)\u001b[0m\n\u001b[1;32m    330\u001b[0m                                    \u001b[0mdiskless\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiskless\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                                    format=format)\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         return cls(ds, mode=mode, writer=writer, opener=opener,\n\u001b[1;32m    334\u001b[0m                    autoclose=autoclose, lock=lock)\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m_open_netcdf4_group\u001b[0;34m(filename, mode, group, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mnetCDF4\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnc4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mclose_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno -51] NetCDF: Unknown file format: b'/OSM/CBR/OA_DCFP/work/squ027/intermediate_products/tmp/ENSO_predictability.oisst_nino34_c0.nc'"
     ]
    }
   ],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    oisst_nino34_c0_ts = (oisst_nino34_full_ts.groupby('time.month') - oisst_nino34_full_ts.sel(time=clim_period).groupby('time.month').mean('time')).drop('month')\n",
    "    oisst_nino34_c0 = doppyo.utils.stack_by_init_date(oisst_nino34_c0_ts, init_dates=pd.date_range('1982-01','2015-12',freq='MS'), N_lead_steps=12).rename('c0')\n",
    "    \n",
    "    oisst_nino34_c0.to_netcdf(dataloc + 'ENSO_predictability.oisst_nino34_c0.nc')\n",
    "else:\n",
    "    oisst_nino34_c0 = xr.open_dataset(dataloc + 'ENSO_predictability.oisst_nino34_c0.nc')['c0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1999','2015')\n",
    "    clim_use = oisst_nino34_full_ts.sel(time=clim_period)\n",
    "    oisst_nino34_c1_ts = oisst_nino34_full_ts.groupby('time').apply(cv_anomalize, clim_ts=clim_use, time_dim='time')\n",
    "    oisst_nino34_c1 = doppyo.utils.stack_by_init_date(oisst_nino34_c1_ts, init_dates=pd.date_range('1982-01','2018-02',freq='MS'), N_lead_steps=12).rename('c1').drop('month')\n",
    "    \n",
    "    oisst_nino34_c1.to_netcdf(dataloc + 'ENSO_predictability.oisst_nino34_c1.nc')\n",
    "else:\n",
    "    oisst_nino34_c1 = xr.open_dataset(dataloc + 'ENSO_predictability.oisst_nino34_c1.nc')['c1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c2 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    oisst_nino34_c2_ts = oisst_nino34_c0_ts\n",
    "    oisst_nino34_c2 = oisst_nino34_c0.rename('c2')\n",
    "    \n",
    "    oisst_nino34_c2.to_netcdf(dataloc + 'ENSO_predictability.oisst_nino34_c2.nc')\n",
    "else:\n",
    "    oisst_nino34_c2 = xr.open_dataset(dataloc + 'ENSO_predictability.oisst_nino34_c2.nc')['c2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c3 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    oisst_nino34_c3_ts = oisst_nino34_c0_ts\n",
    "    oisst_nino34_c3 = oisst_nino34_c0.rename('c3')\n",
    "    \n",
    "    oisst_nino34_c3.to_netcdf(dataloc + 'ENSO_predictability.oisst_nino34_c3.nc')\n",
    "else:\n",
    "    oisst_nino34_c3 = xr.open_dataset(dataloc + 'ENSO_predictability.oisst_nino34_c3.nc')['c3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 full anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','2015')\n",
    "    clim_use = oisst_nino34_full_ts.sel(time=clim_period)\n",
    "    oisst_nino34_c1full_ts = oisst_nino34_full_ts.groupby('time').apply(cv_anomalize, clim_ts=clim_use, time_dim='time')\n",
    "    oisst_nino34_c1full = doppyo.utils.stack_by_init_date(oisst_nino34_c1full_ts, init_dates=pd.date_range('1982-01','2018-02',freq='MS'), N_lead_steps=12).rename('c1full').drop('month')\n",
    "    \n",
    "    oisst_nino34_c1full.to_netcdf(dataloc + 'ENSO_predictability.oisst_nino34_c1full.nc')\n",
    "else:\n",
    "    oisst_nino34_c1full = xr.open_dataset(dataloc + 'ENSO_predictability.oisst_nino34_c1full.nc')['c1full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 ncv anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1999','2015')\n",
    "    oisst_nino34_c1ncv_ts = (oisst_nino34_full_ts.groupby('time.month') - oisst_nino34_full_ts.sel(time=clim_period).groupby('time.month').mean('time')).drop('month')\n",
    "    oisst_nino34_c1ncv = doppyo.utils.stack_by_init_date(oisst_nino34_c1ncv_ts, init_dates=pd.date_range('1982-01','2015-12',freq='MS'), N_lead_steps=12).rename('c1ncv')\n",
    "    \n",
    "    oisst_nino34_c1ncv.to_netcdf(dataloc + 'ENSO_predictability.oisst_nino34_c1ncv.nc')\n",
    "else:\n",
    "    oisst_nino34_c1ncv = xr.open_dataset(dataloc + 'ENSO_predictability.oisst_nino34_c1ncv.nc')['c1ncv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oisst_nino34 = oisst_nino34_full.to_dataset()\n",
    "oisst_nino34['c0'] = oisst_nino34_c0\n",
    "oisst_nino34['c1'] = oisst_nino34_c1\n",
    "oisst_nino34['c2'] = oisst_nino34_c2\n",
    "oisst_nino34['c3'] = oisst_nino34_c3\n",
    "oisst_nino34['c1full'] = oisst_nino34_c1full\n",
    "oisst_nino34['c1ncv'] = oisst_nino34_c1ncv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Hadley ISST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    had_sst_full_ts = xr.open_dataset('/OSM/CBR/OA_DCFP/work/squ027/intermediate_products/tmp/ENSO_predictability.had_sst_raw_ts.nc')['sst'].rename('hadsst')\n",
    "    had_nino34_full_ts = doppyo.diagnostic.nino34(had_sst_full_ts).rename('full_ts')\n",
    "    had_nino34_full = doppyo.utils.stack_by_init_date(had_nino34_full_ts, init_dates=pd.date_range('1982-01','2015-12',freq='MS'), N_lead_steps=12).rename('full')\n",
    "    \n",
    "    had_nino34_full_ts.to_netcdf(dataloc + 'ENSO_predictability.had_nino34_full_ts.nc')\n",
    "    had_nino34_full.to_netcdf(dataloc + 'ENSO_predictability.had_nino34_full.nc')\n",
    "else:\n",
    "    had_nino34_full_ts = xr.open_dataset(dataloc + 'ENSO_predictability.had_nino34_full_ts.nc')['full_ts']\n",
    "    had_nino34_full = xr.open_dataset(dataloc + 'ENSO_predictability.had_nino34_full.nc')['full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c0 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    had_nino34_c0_ts = (had_nino34_full_ts.groupby('time.month') - had_nino34_full_ts.sel(time=clim_period).groupby('time.month').mean('time')).drop('month')\n",
    "    had_nino34_c0 = doppyo.utils.stack_by_init_date(had_nino34_c0_ts, init_dates=pd.date_range('1982-01','2015-12',freq='MS'), N_lead_steps=12).rename('c0')\n",
    "    \n",
    "    had_nino34_c0.to_netcdf(dataloc + 'ENSO_predictability.had_nino34_c0.nc')\n",
    "else:\n",
    "    had_nino34_c0 = xr.open_dataset(dataloc + 'ENSO_predictability.had_nino34_c0.nc')['c0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1999','2015')\n",
    "    clim_use = had_nino34_full_ts.sel(time=clim_period)\n",
    "    had_nino34_c1_ts = had_nino34_full_ts.groupby('time').apply(cv_anomalize, clim_ts=clim_use, time_dim='time')\n",
    "    had_nino34_c1 = doppyo.utils.stack_by_init_date(had_nino34_c1_ts, init_dates=pd.date_range('1982-01','2018-02',freq='MS'), N_lead_steps=12).rename('c1').drop('month')\n",
    "    \n",
    "    had_nino34_c1.to_netcdf(dataloc + 'ENSO_predictability.had_nino34_c1.nc')\n",
    "else:\n",
    "    had_nino34_c1 = xr.open_dataset(dataloc + 'ENSO_predictability.had_nino34_c1.nc')['c1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c2 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    had_nino34_c2_ts = had_nino34_c0_ts\n",
    "    had_nino34_c2 = had_nino34_c0.rename('c2')\n",
    "    \n",
    "    had_nino34_c2.to_netcdf(dataloc + 'ENSO_predictability.had_nino34_c2.nc')\n",
    "else:\n",
    "    had_nino34_c2 = xr.open_dataset(dataloc + 'ENSO_predictability.had_nino34_c2.nc')['c2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c3 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    had_nino34_c3_ts = had_nino34_c0_ts\n",
    "    had_nino34_c3 = had_nino34_c0.rename('c3')\n",
    "    \n",
    "    had_nino34_c3.to_netcdf(dataloc + 'ENSO_predictability.had_nino34_c3.nc')\n",
    "else:\n",
    "    had_nino34_c3 = xr.open_dataset(dataloc + 'ENSO_predictability.had_nino34_c3.nc')['c3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 full anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','2015')\n",
    "    clim_use = had_nino34_full_ts.sel(time=clim_period)\n",
    "    had_nino34_c1full_ts = had_nino34_full_ts.groupby('time').apply(cv_anomalize, clim_ts=clim_use, time_dim='time')\n",
    "    had_nino34_c1full = doppyo.utils.stack_by_init_date(had_nino34_c1full_ts, init_dates=pd.date_range('1982-01','2018-02',freq='MS'), N_lead_steps=12).rename('c1full').drop('month')\n",
    "    \n",
    "    had_nino34_c1full.to_netcdf(dataloc + 'ENSO_predictability.had_nino34_c1full.nc')\n",
    "else:\n",
    "    had_nino34_c1full = xr.open_dataset(dataloc + 'ENSO_predictability.had_nino34_c1full.nc')['c1full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 ncv anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1999','2015')\n",
    "    had_nino34_c1ncv_ts = (had_nino34_full_ts.groupby('time.month') - had_nino34_full_ts.sel(time=clim_period).groupby('time.month').mean('time')).drop('month')\n",
    "    had_nino34_c1ncv = doppyo.utils.stack_by_init_date(had_nino34_c1ncv_ts, init_dates=pd.date_range('1982-01','2015-12',freq='MS'), N_lead_steps=12).rename('c1ncv')\n",
    "    \n",
    "    had_nino34_c1ncv.to_netcdf(dataloc + 'ENSO_predictability.had_nino34_c1ncv.nc')\n",
    "else:\n",
    "    had_nino34_c1ncv = xr.open_dataset(dataloc + 'ENSO_predictability.had_nino34_c1ncv.nc')['c1ncv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "had_nino34 = had_nino34_full.to_dataset()\n",
    "had_nino34['c0'] = had_nino34_c0\n",
    "had_nino34['c1'] = had_nino34_c1\n",
    "had_nino34['c2'] = had_nino34_c2\n",
    "had_nino34['c3'] = had_nino34_c3\n",
    "had_nino34['c1full'] = had_nino34_c1full\n",
    "had_nino34['c1ncv'] = had_nino34_c1ncv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose which obs to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_2_use = oisst_nino34 # had_nino34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw COLA-RSMAS-CCSM4 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    filelist = glob.glob('/OSM/CBR/OA_DCFP/data2/model_output/NMME/phase1/COLA-RSMAS-CCSM4/monthly/sst_mon_COLA-RSMAS-CCSM4_198201_r*i1p1_198201-201811.nc')\n",
    "    filelist.sort(key=natural_keys)\n",
    "\n",
    "    cola_sst_raw = xr.open_mfdataset(filelist, decode_times=False)['sst'] \\\n",
    "                     .rename({'X' : 'lon', 'Y' : 'lat', 'M' : 'ensemble', \n",
    "                              'L' : 'lead_time', 'S' : 'init_date'}).compute()\n",
    "\n",
    "    basedate = np.datetime64(cola_sst_raw.init_date.units.split(' ')[2])\n",
    "    cola_sst_raw['init_date'] = np.array([doppyo.sugar.month_delta(basedate, int(shift)) for shift in cola_sst_raw.init_date.values])\n",
    "\n",
    "    cola_sst_raw['lead_time'] = [int(lead_time - 0.5) for lead_time in cola_sst_raw['lead_time']]\n",
    "    cola_sst_raw.lead_time.attrs['units'] = 'MS'\n",
    "\n",
    "    cola_sst_raw['ensemble'] = [int(ensemble) for ensemble in cola_sst_raw['ensemble']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute nino3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    cola_nino34_full = doppyo.diagnostic.nino34(cola_sst_raw).rename('full')\n",
    "    \n",
    "    cola_nino34_full.to_netcdf(dataloc + 'ENSO_predictability.cola_nino34_full.nc')\n",
    "else:\n",
    "    cola_nino34_full = xr.open_dataset(dataloc + 'ENSO_predictability.cola_nino34_full.nc')['full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c0 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    clim = obs_2_use['full'].sel(init_date=clim_period, lead_time=0).groupby('init_date.month').mean('init_date').drop('lead_time')\n",
    "    cola_nino34_c0 = cola_nino34_full.groupby('init_date').apply(lambda_anomalize, clim=clim).rename('c0')\n",
    "    \n",
    "    cola_nino34_c0.to_netcdf(dataloc + 'ENSO_predictability.cola_nino34_c0.nc')\n",
    "else:\n",
    "    cola_nino34_c0 = xr.open_dataset(dataloc + 'ENSO_predictability.cola_nino34_c0.nc')['c0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1999','2015')\n",
    "    cola_nino34_full_use = cola_nino34_full.sel(init_date=clim_period).mean('ensemble')\n",
    "    cola_nino34_c1 = cola_nino34_full.groupby('init_date').apply(cv_anomalize, clim_ts=cola_nino34_full_use).rename('c1')\n",
    "    \n",
    "    cola_nino34_c1.to_netcdf(dataloc + 'ENSO_predictability.cola_nino34_c1.nc')\n",
    "else:\n",
    "    cola_nino34_c1 = xr.open_dataset(dataloc + 'ENSO_predictability.cola_nino34_c1.nc')['c1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c2 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "\n",
    "    clim = cola_nino34_full.sel(init_date=clim_period).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    cola_nino34_c2 = (cola_nino34_full.groupby('init_date.month') - clim).rename('c2')\n",
    "    \n",
    "    cola_nino34_c2.to_netcdf(dataloc + 'ENSO_predictability.cola_nino34_c2.nc')\n",
    "else:\n",
    "    cola_nino34_c2 = xr.open_dataset(dataloc + 'ENSO_predictability.cola_nino34_c2.nc')['c2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c3 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    \n",
    "    init_dates = cola_nino34_c0.sel(init_date=clim_period).init_date.copy()\n",
    "    lead_times = cola_nino34_c0.sel(init_date=clim_period).lead_time.copy()\n",
    "    init_dates.values = np.arange(len(init_dates))\n",
    "    mask = (init_dates + lead_times) <= init_dates[-1]\n",
    "\n",
    "    fcst_er = (cola_nino34_c0.where(mask) - obs_2_use['c0'].where(mask)).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    \n",
    "    cola_nino34_c3 = (cola_nino34_c0.groupby('init_date.month') - fcst_er).rename('c3')\n",
    "\n",
    "    cola_nino34_c3.to_netcdf(dataloc + 'ENSO_predictability.cola_nino34_c3.nc')\n",
    "else:\n",
    "    cola_nino34_c3 = xr.open_dataset(dataloc + 'ENSO_predictability.cola_nino34_c3.nc')['c3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The **c2** anomalies are similar to the **c3** anomalies. Let's see how they are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cola_nino34_c2 - cola_nino34_c3).mean('ensemble').plot(vmin=-0.2, vmax=0.2, cmap='bwr');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one instead computes **c3** using the forecast error computed as the difference between the lead-time-dependent model climatology and the observed climatology over the period 1982-1998, then **c3** -> **c2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    fcst_er = cola_nino34_c0.sel(init_date=clim_period).groupby('init_date.month').mean(['init_date','ensemble']) - \\\n",
    "              obs_2_use['c0'].sel(init_date=clim_period, lead_time=0).groupby('init_date.month').mean('init_date')\n",
    "    \n",
    "    cola_nino34_c3_tmp = cola_nino34_c0.groupby('init_date.month') - fcst_er\n",
    "\n",
    "    (cola_nino34_c2 - cola_nino34_c3_tmp).mean('ensemble').plot(vmin=-0.2, vmax=0.2, cmap='bwr');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if one computes **c0** using the \"lead-time-dependent\" observed climatology using **only** data within the period 1982-1998 and computes the errors as Delsole does, then **c3** -> **c2**, if **c2** anomalies are computed in a consistent way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    \n",
    "    init_dates = cola_nino34_c0_tmp.sel(init_date=clim_period).init_date.copy()\n",
    "    lead_times = cola_nino34_c0_tmp.sel(init_date=clim_period).lead_time.copy()\n",
    "    init_dates.values = np.arange(len(init_dates))\n",
    "    mask = (init_dates + lead_times) <= init_dates[-1]\n",
    "    \n",
    "    clim = obs_2_use['full'].where(mask).groupby('init_date.month').mean('init_date')\n",
    "    cola_nino34_c0_tmp = cola_nino34_full.groupby('init_date.month') - clim\n",
    "    obs_c0_tmp = obs_2_use['full'].groupby('init_date.month') - clim\n",
    "\n",
    "    fcst_er = (cola_nino34_c0_tmp.where(mask) - obs_c0_tmp.where(mask)).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    \n",
    "    cola_nino34_c3_tmp = cola_nino34_c0_tmp.groupby('init_date.month') - fcst_er\n",
    "    \n",
    "    clim = cola_nino34_full.where(mask).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    cola_nino34_c2_tmp = cola_nino34_full.groupby('init_date.month') - clim\n",
    "\n",
    "    (cola_nino34_c2_tmp - cola_nino34_c3_tmp).mean('ensemble').plot(vmin=-0.2, vmax=0.2, cmap='bwr');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about performing the bias correction on the full field over the full period and then computing anomalies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    \n",
    "    init_dates = cola_nino34_full.sel(init_date=clim_period).init_date.copy()\n",
    "    lead_times = cola_nino34_full.sel(init_date=clim_period).lead_time.copy()\n",
    "    init_dates.values = np.arange(len(init_dates))\n",
    "    mask = (init_dates + lead_times) <= init_dates[-1]\n",
    "\n",
    "    fcst_er = (cola_nino34_full.where(mask) - obs_2_use['full'].where(mask)).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    \n",
    "    cola_nino34_tmp = cola_nino34_full.groupby('init_date.month') - fcst_er\n",
    "   \n",
    "    clim = cola_nino34_tmp.sel(init_date=clim_period).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    \n",
    "    cola_nino34_c3_tmp = cola_nino34_full.groupby('init_date.month') - clim\n",
    "    \n",
    "    (cola_nino34_c3_tmp - cola_nino34_c3_tmp).mean('ensemble').plot(vmin=-0.2, vmax=0.2, cmap='bwr');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 full anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','2015')\n",
    "    cola_nino34_full_use = cola_nino34_full.sel(init_date=clim_period).mean('ensemble')\n",
    "    cola_nino34_c1full = cola_nino34_full.groupby('init_date').apply(cv_anomalize, clim_ts=cola_nino34_full_use).rename('c1full')\n",
    "    \n",
    "    cola_nino34_c1full.to_netcdf(dataloc + 'ENSO_predictability.cola_nino34_c1full.nc')\n",
    "else:\n",
    "    cola_nino34_c1full = xr.open_dataset(dataloc + 'ENSO_predictability.cola_nino34_c1full.nc')['c1full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 ncv anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1999','2015')\n",
    "\n",
    "    clim = cola_nino34_full.sel(init_date=clim_period).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    cola_nino34_c1ncv = (cola_nino34_full.groupby('init_date.month') - clim).rename('c1ncv')\n",
    "    \n",
    "    cola_nino34_c1ncv.to_netcdf(dataloc + 'ENSO_predictability.cola_nino34_c1ncv.nc')\n",
    "else:\n",
    "    cola_nino34_c1ncv = xr.open_dataset(dataloc + 'ENSO_predictability.cola_nino34_c1ncv.nc')['c1ncv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cola_nino34 = cola_nino34_full.to_dataset()\n",
    "cola_nino34['c0'] = cola_nino34_c0\n",
    "cola_nino34['c1'] = cola_nino34_c1\n",
    "cola_nino34['c2'] = cola_nino34_c2\n",
    "cola_nino34['c3'] = cola_nino34_c3\n",
    "cola_nino34['c1full'] = cola_nino34_c1full\n",
    "cola_nino34['c1ncv'] = cola_nino34_c1ncv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw GFDL-CM2p1-aer04 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    filelist = glob.glob('/OSM/CBR/OA_DCFP/data2/model_output/NMME/phase1/GFDL-CM2p1-aer04/monthly/sst_mon_GFDL-CM2p1-aer04_198201_r*i1p1_198201-201811.nc')\n",
    "    filelist.sort(key=natural_keys)\n",
    "\n",
    "    aer04_sst_raw = xr.open_mfdataset(filelist, decode_times=False)['sst'] \\\n",
    "                     .rename({'X' : 'lon', 'Y' : 'lat', 'M' : 'ensemble', \n",
    "                              'L' : 'lead_time', 'S' : 'init_date'}).compute() - 273.15\n",
    "\n",
    "    basedate = np.datetime64(aer04_sst_raw.init_date.units.split(' ')[2])\n",
    "    aer04_sst_raw['init_date'] = np.array([doppyo.sugar.month_delta(basedate, int(shift)) for shift in aer04_sst_raw.init_date.values])\n",
    "\n",
    "    aer04_sst_raw['lead_time'] = [int(lead_time - 0.5) for lead_time in aer04_sst_raw['lead_time']]\n",
    "    aer04_sst_raw.lead_time.attrs['units'] = 'MS'\n",
    "\n",
    "    aer04_sst_raw['ensemble'] = [int(ensemble) for ensemble in aer04_sst_raw['ensemble']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute nino3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    aer04_nino34_full = doppyo.diagnostic.nino34(aer04_sst_raw).rename('full')\n",
    "    \n",
    "    aer04_nino34_full.to_netcdf(dataloc + 'ENSO_predictability.aer04_nino34_full.nc')\n",
    "else:\n",
    "    aer04_nino34_full = xr.open_dataset(dataloc + 'ENSO_predictability.aer04_nino34_full.nc')['full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c0 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    clim = obs_2_use['full'].sel(init_date=clim_period, lead_time=0).groupby('init_date.month').mean('init_date').drop('lead_time')\n",
    "    aer04_nino34_c0 = aer04_nino34_full.groupby('init_date').apply(lambda_anomalize, clim=clim).rename('c0')\n",
    "    \n",
    "    aer04_nino34_c0.to_netcdf(dataloc + 'ENSO_predictability.aer04_nino34_c0.nc')\n",
    "else:\n",
    "    aer04_nino34_c0 = xr.open_dataset(dataloc + 'ENSO_predictability.aer04_nino34_c0.nc')['c0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1999','2015')\n",
    "    aer04_nino34_full_use = aer04_nino34_full.sel(init_date=clim_period).mean('ensemble')\n",
    "    aer04_nino34_c1 = aer04_nino34_full.groupby('init_date').apply(cv_anomalize, clim_ts=aer04_nino34_full_use).rename('c1')\n",
    "    \n",
    "    aer04_nino34_c1.to_netcdf(dataloc + 'ENSO_predictability.aer04_nino34_c1.nc')\n",
    "else:\n",
    "    aer04_nino34_c1 = xr.open_dataset(dataloc + 'ENSO_predictability.aer04_nino34_c1.nc')['c1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c2 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "\n",
    "    clim = aer04_nino34_full.sel(init_date=clim_period).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    aer04_nino34_c2 = (aer04_nino34_full.groupby('init_date.month') - clim).rename('c2')\n",
    "    \n",
    "    aer04_nino34_c2.to_netcdf(dataloc + 'ENSO_predictability.aer04_nino34_c2.nc')\n",
    "else:\n",
    "    aer04_nino34_c2 = xr.open_dataset(dataloc + 'ENSO_predictability.aer04_nino34_c2.nc')['c2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c3 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    \n",
    "    init_dates = aer04_nino34_c0.sel(init_date=clim_period).init_date.copy()\n",
    "    lead_times = aer04_nino34_c0.sel(init_date=clim_period).lead_time.copy()\n",
    "    init_dates.values = np.arange(len(init_dates))\n",
    "    mask = (init_dates + lead_times) <= init_dates[-1]\n",
    "\n",
    "    fcst_er = (aer04_nino34_c0.where(mask) - obs_2_use['c0'].where(mask)).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    \n",
    "    aer04_nino34_c3 = (aer04_nino34_c0.groupby('init_date.month') - fcst_er).rename('c3')\n",
    "\n",
    "    aer04_nino34_c3.to_netcdf(dataloc + 'ENSO_predictability.aer04_nino34_c3.nc')\n",
    "else:\n",
    "    aer04_nino34_c3 = xr.open_dataset(dataloc + 'ENSO_predictability.aer04_nino34_c3.nc')['c3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 full anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','2015')\n",
    "    aer04_nino34_full_use = aer04_nino34_full.sel(init_date=clim_period).mean('ensemble')\n",
    "    aer04_nino34_c1full = aer04_nino34_full.groupby('init_date').apply(cv_anomalize, clim_ts=aer04_nino34_full_use).rename('c1full')\n",
    "    \n",
    "    aer04_nino34_c1full.to_netcdf(dataloc + 'ENSO_predictability.aer04_nino34_c1full.nc')\n",
    "else:\n",
    "    aer04_nino34_c1full = xr.open_dataset(dataloc + 'ENSO_predictability.aer04_nino34_c1full.nc')['c1full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 ncv anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1999','2015')\n",
    "\n",
    "    clim = aer04_nino34_full.sel(init_date=clim_period).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    aer04_nino34_c1ncv = (aer04_nino34_full.groupby('init_date.month') - clim).rename('c1ncv')\n",
    "    \n",
    "    aer04_nino34_c1ncv.to_netcdf(dataloc + 'ENSO_predictability.aer04_nino34_c1ncv.nc')\n",
    "else:\n",
    "    aer04_nino34_c1ncv = xr.open_dataset(dataloc + 'ENSO_predictability.aer04_nino34_c1ncv.nc')['c1ncv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aer04_nino34 = aer04_nino34_full.to_dataset()\n",
    "aer04_nino34['c0'] = aer04_nino34_c0\n",
    "aer04_nino34['c1'] = aer04_nino34_c1\n",
    "aer04_nino34['c2'] = aer04_nino34_c2\n",
    "aer04_nino34['c3'] = aer04_nino34_c3\n",
    "aer04_nino34['c1full'] = aer04_nino34_c1full\n",
    "aer04_nino34['c1ncv'] = aer04_nino34_c1ncv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw GFDL-CM2p5-FLOR-A06 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    filelist = glob.glob('/OSM/CBR/OA_DCFP/data2/model_output/NMME/phase1/GFDL-CM2p5-FLOR-A06/monthly/sst_mon_GFDL-CM2p5-FLOR-A06_198201_r*i1p1_198201-201811.nc')\n",
    "    filelist.sort(key=natural_keys)\n",
    "\n",
    "    florA_sst_raw = xr.open_mfdataset(filelist, decode_times=False)['sst'] \\\n",
    "                     .rename({'X' : 'lon', 'Y' : 'lat', 'M' : 'ensemble', \n",
    "                              'L' : 'lead_time', 'S' : 'init_date'}).compute()\n",
    "\n",
    "    basedate = np.datetime64(florA_sst_raw.init_date.units.split(' ')[2])\n",
    "    florA_sst_raw['init_date'] = np.array([doppyo.sugar.month_delta(basedate, int(shift)) for shift in florA_sst_raw.init_date.values])\n",
    "\n",
    "    florA_sst_raw['lead_time'] = [int(lead_time - 0.5) for lead_time in florA_sst_raw['lead_time']]\n",
    "    florA_sst_raw.lead_time.attrs['units'] = 'MS'\n",
    "\n",
    "    florA_sst_raw['ensemble'] = [int(ensemble) for ensemble in florA_sst_raw['ensemble']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute nino3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    florA_nino34_full = doppyo.diagnostic.nino34(florA_sst_raw).rename('full')\n",
    "    \n",
    "    florA_nino34_full.to_netcdf(dataloc + 'ENSO_predictability.florA_nino34_full.nc')\n",
    "else:\n",
    "    florA_nino34_full = xr.open_dataset(dataloc + 'ENSO_predictability.florA_nino34_full.nc')['full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c0 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    clim = obs_2_use['full'].sel(init_date=clim_period, lead_time=0).groupby('init_date.month').mean('init_date').drop('lead_time')\n",
    "    florA_nino34_c0 = florA_nino34_full.groupby('init_date').apply(lambda_anomalize, clim=clim).rename('c0')\n",
    "    \n",
    "    florA_nino34_c0.to_netcdf(dataloc + 'ENSO_predictability.florA_nino34_c0.nc')\n",
    "else:\n",
    "    florA_nino34_c0 = xr.open_dataset(dataloc + 'ENSO_predictability.florA_nino34_c0.nc')['c0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1999','2015')\n",
    "    florA_nino34_full_use = florA_nino34_full.sel(init_date=clim_period).mean('ensemble')\n",
    "    florA_nino34_c1 = florA_nino34_full.groupby('init_date').apply(cv_anomalize, clim_ts=florA_nino34_full_use).rename('c1')\n",
    "    \n",
    "    florA_nino34_c1.to_netcdf(dataloc + 'ENSO_predictability.florA_nino34_c1.nc')\n",
    "else:\n",
    "    florA_nino34_c1 = xr.open_dataset(dataloc + 'ENSO_predictability.florA_nino34_c1.nc')['c1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c2 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "\n",
    "    clim = florA_nino34_full.sel(init_date=clim_period).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    florA_nino34_c2 = (florA_nino34_full.groupby('init_date.month') - clim).rename('c2')\n",
    "    \n",
    "    florA_nino34_c2.to_netcdf(dataloc + 'ENSO_predictability.florA_nino34_c2.nc')\n",
    "else:\n",
    "    florA_nino34_c2 = xr.open_dataset(dataloc + 'ENSO_predictability.florA_nino34_c2.nc')['c2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c3 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    \n",
    "    init_dates = florA_nino34_c0.sel(init_date=clim_period).init_date.copy()\n",
    "    lead_times = florA_nino34_c0.sel(init_date=clim_period).lead_time.copy()\n",
    "    init_dates.values = np.arange(len(init_dates))\n",
    "    mask = (init_dates + lead_times) <= init_dates[-1]\n",
    "\n",
    "    fcst_er = (florA_nino34_c0.where(mask) - obs_2_use['c0'].where(mask)).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    \n",
    "    florA_nino34_c3 = (florA_nino34_c0.groupby('init_date.month') - fcst_er).rename('c3')\n",
    "\n",
    "    florA_nino34_c3.to_netcdf(dataloc + 'ENSO_predictability.florA_nino34_c3.nc')\n",
    "else:\n",
    "    florA_nino34_c3 = xr.open_dataset(dataloc + 'ENSO_predictability.florA_nino34_c3.nc')['c3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 full anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','2015')\n",
    "    florA_nino34_full_use = florA_nino34_full.sel(init_date=clim_period).mean('ensemble')\n",
    "    florA_nino34_c1full = florA_nino34_full.groupby('init_date').apply(cv_anomalize, clim_ts=florA_nino34_full_use).rename('c1full')\n",
    "    \n",
    "    florA_nino34_c1full.to_netcdf(dataloc + 'ENSO_predictability.florA_nino34_c1full.nc')\n",
    "else:\n",
    "    florA_nino34_c1full = xr.open_dataset(dataloc + 'ENSO_predictability.florA_nino34_c1full.nc')['c1full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 ncv anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1999','2015')\n",
    "\n",
    "    clim = florA_nino34_full.sel(init_date=clim_period).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    florA_nino34_c1ncv = (florA_nino34_full.groupby('init_date.month') - clim).rename('c1ncv')\n",
    "    \n",
    "    florA_nino34_c1ncv.to_netcdf(dataloc + 'ENSO_predictability.florA_nino34_c1ncv.nc')\n",
    "else:\n",
    "    florA_nino34_c1ncv = xr.open_dataset(dataloc + 'ENSO_predictability.florA_nino34_c1ncv.nc')['c1ncv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "florA_nino34 = florA_nino34_full.to_dataset()\n",
    "florA_nino34['c0'] = florA_nino34_c0\n",
    "florA_nino34['c1'] = florA_nino34_c1\n",
    "florA_nino34['c2'] = florA_nino34_c2\n",
    "florA_nino34['c3'] = florA_nino34_c3\n",
    "florA_nino34['c1full'] = florA_nino34_c1full\n",
    "florA_nino34['c1ncv'] = florA_nino34_c1ncv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw GFDL-CM2p5-FLOR-B01 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    filelist = glob.glob('/OSM/CBR/OA_DCFP/data2/model_output/NMME/phase1/GFDL-CM2p5-FLOR-B01/monthly/sst_mon_GFDL-CM2p5-FLOR-B01_198201_r*i1p1_198201-201811.nc')\n",
    "    filelist.sort(key=natural_keys)\n",
    "\n",
    "    florB_sst_raw = xr.open_mfdataset(filelist, decode_times=False)['sst'] \\\n",
    "                     .rename({'X' : 'lon', 'Y' : 'lat', 'M' : 'ensemble', \n",
    "                              'L' : 'lead_time', 'S' : 'init_date'}).compute()\n",
    "\n",
    "    basedate = np.datetime64(florB_sst_raw.init_date.units.split(' ')[2])\n",
    "    florB_sst_raw['init_date'] = np.array([doppyo.sugar.month_delta(basedate, int(shift)) for shift in florB_sst_raw.init_date.values])\n",
    "\n",
    "    florB_sst_raw['lead_time'] = [int(lead_time - 0.5) for lead_time in florB_sst_raw['lead_time']]\n",
    "    florB_sst_raw.lead_time.attrs['units'] = 'MS'\n",
    "\n",
    "    florB_sst_raw['ensemble'] = [int(ensemble) for ensemble in florB_sst_raw['ensemble']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute nino3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    florB_nino34_full = doppyo.diagnostic.nino34(florB_sst_raw).rename('full')\n",
    "\n",
    "    florB_nino34_full.to_netcdf(dataloc + 'ENSO_predictability.florB_nino34_full.nc')\n",
    "else:\n",
    "    florB_nino34_full = xr.open_dataset(dataloc + 'ENSO_predictability.florB_nino34_full.nc')['full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c0 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    clim = obs_2_use['full'].sel(init_date=clim_period, lead_time=0).groupby('init_date.month').mean('init_date').drop('lead_time')\n",
    "    florB_nino34_c0 = florB_nino34_full.groupby('init_date').apply(lambda_anomalize, clim=clim).rename('c0')\n",
    "    \n",
    "    florB_nino34_c0.to_netcdf(dataloc + 'ENSO_predictability.florB_nino34_c0.nc')\n",
    "else:\n",
    "    florB_nino34_c0 = xr.open_dataset(dataloc + 'ENSO_predictability.florB_nino34_c0.nc')['c0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1999','2015')\n",
    "    florB_nino34_full_use = florB_nino34_full.sel(init_date=clim_period).mean('ensemble')\n",
    "    florB_nino34_c1 = florB_nino34_full.groupby('init_date').apply(cv_anomalize, clim_ts=florB_nino34_full_use).rename('c1')\n",
    "    \n",
    "    florB_nino34_c1.to_netcdf(dataloc + 'ENSO_predictability.florB_nino34_c1.nc')\n",
    "else:\n",
    "    florB_nino34_c1 = xr.open_dataset(dataloc + 'ENSO_predictability.florB_nino34_c1.nc')['c1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c2 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "\n",
    "    clim = florB_nino34_full.sel(init_date=clim_period).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    florB_nino34_c2 = (florB_nino34_full.groupby('init_date.month') - clim).rename('c2')\n",
    "    \n",
    "    florB_nino34_c2.to_netcdf(dataloc + 'ENSO_predictability.florB_nino34_c2.nc')\n",
    "else:\n",
    "    florB_nino34_c2 = xr.open_dataset(dataloc + 'ENSO_predictability.florB_nino34_c2.nc')['c2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c3 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    \n",
    "    init_dates = florB_nino34_c0.sel(init_date=clim_period).init_date.copy()\n",
    "    lead_times = florB_nino34_c0.sel(init_date=clim_period).lead_time.copy()\n",
    "    init_dates.values = np.arange(len(init_dates))\n",
    "    mask = (init_dates + lead_times) <= init_dates[-1]\n",
    "\n",
    "    fcst_er = (florB_nino34_c0.where(mask) - obs_2_use['c0'].where(mask)).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    \n",
    "    florB_nino34_c3 = (florB_nino34_c0.groupby('init_date.month') - fcst_er).rename('c3')\n",
    "\n",
    "    florB_nino34_c3.to_netcdf(dataloc + 'ENSO_predictability.florB_nino34_c3.nc')\n",
    "else:\n",
    "    florB_nino34_c3 = xr.open_dataset(dataloc + 'ENSO_predictability.florB_nino34_c3.nc')['c3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 full anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','2015')\n",
    "    florB_nino34_full_use = florB_nino34_full.sel(init_date=clim_period).mean('ensemble')\n",
    "    florB_nino34_c1full = florB_nino34_full.groupby('init_date').apply(cv_anomalize, clim_ts=florB_nino34_full_use).rename('c1full')\n",
    "    \n",
    "    florB_nino34_c1full.to_netcdf(dataloc + 'ENSO_predictability.florB_nino34_c1full.nc')\n",
    "else:\n",
    "    florB_nino34_c1full = xr.open_dataset(dataloc + 'ENSO_predictability.florB_nino34_c1full.nc')['c1full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 ncv anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1999','2015')\n",
    "\n",
    "    clim = florB_nino34_full.sel(init_date=clim_period).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    florB_nino34_c1ncv = (florB_nino34_full.groupby('init_date.month') - clim).rename('c1ncv')\n",
    "    \n",
    "    florB_nino34_c1ncv.to_netcdf(dataloc + 'ENSO_predictability.florB_nino34_c1ncv.nc')\n",
    "else:\n",
    "    florB_nino34_c1ncv = xr.open_dataset(dataloc + 'ENSO_predictability.florB_nino34_c1ncv.nc')['c1ncv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "florB_nino34 = florB_nino34_full.to_dataset()\n",
    "florB_nino34['c0'] = florB_nino34_c0\n",
    "florB_nino34['c1'] = florB_nino34_c1\n",
    "florB_nino34['c2'] = florB_nino34_c2\n",
    "florB_nino34['c3'] = florB_nino34_c3\n",
    "florB_nino34['c1full'] = florB_nino34_c1full\n",
    "florB_nino34['c1ncv'] = florB_nino34_c1ncv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw CMC CanCM3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    folder = '/OSM/CBR/OA_DCFP/data2/model_output/NMME/phase1/CMC_CanCM3/monthly/'\n",
    "    hcstfiles = 'sst_mon_CanCM3_198101*.nc'\n",
    "    fcstfiles = 'sst_mon_CanCM3_201101*.nc'\n",
    "\n",
    "    hcstlist = glob.glob(folder + hcstfiles)\n",
    "    hcstlist.sort(key=natural_keys)\n",
    "    fcstlist = glob.glob(folder + fcstfiles)\n",
    "    fcstlist.sort(key=natural_keys)\n",
    "\n",
    "    cm3_sst_raw = xr.concat([xr.open_mfdataset(hcstlist, decode_times=False)['sst'] - 273.15,\n",
    "                             xr.open_mfdataset(fcstlist, decode_times=False)['sst'] - 273.15], dim='S') \\\n",
    "                    .rename({'X' : 'lon', 'Y' : 'lat', 'M' : 'ensemble', \n",
    "                             'L' : 'lead_time', 'S' : 'init_date'}).compute()\n",
    "\n",
    "    basedate = np.datetime64(cm3_sst_raw.init_date.units.split(' ')[2])\n",
    "    cm3_sst_raw['init_date'] = np.array([doppyo.sugar.month_delta(basedate, int(shift)) for shift in cm3_sst_raw.init_date.values])\n",
    "\n",
    "    cm3_sst_raw['lead_time'] = [int(lead_time - 0.5) for lead_time in cm3_sst_raw['lead_time']]\n",
    "    cm3_sst_raw.lead_time.attrs['units'] = 'MS'\n",
    "\n",
    "    cm3_sst_raw['ensemble'] = [int(ensemble) for ensemble in cm3_sst_raw['ensemble']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute nino3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    cm3_nino34_full = doppyo.diagnostic.nino34(cm3_sst_raw).rename('full')\n",
    "\n",
    "    cm3_nino34_full.to_netcdf(dataloc + 'ENSO_predictability.cm3_nino34_full.nc')\n",
    "else:\n",
    "    cm3_nino34_full = xr.open_dataset(dataloc + 'ENSO_predictability.cm3_nino34_full.nc')['full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c0 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    clim = obs_2_use['full'].sel(init_date=clim_period, lead_time=0).groupby('init_date.month').mean('init_date').drop('lead_time')\n",
    "    cm3_nino34_c0 = cm3_nino34_full.groupby('init_date').apply(lambda_anomalize, clim=clim).rename('c0')\n",
    "    \n",
    "    cm3_nino34_c0.to_netcdf(dataloc + 'ENSO_predictability.cm3_nino34_c0.nc')\n",
    "else:\n",
    "    cm3_nino34_c0 = xr.open_dataset(dataloc + 'ENSO_predictability.cm3_nino34_c0.nc')['c0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1999','2015')\n",
    "    cm3_nino34_full_use = cm3_nino34_full.sel(init_date=clim_period).mean('ensemble')\n",
    "    cm3_nino34_c1 = cm3_nino34_full.groupby('init_date').apply(cv_anomalize, clim_ts=cm3_nino34_full_use).rename('c1')\n",
    "    \n",
    "    cm3_nino34_c1.to_netcdf(dataloc + 'ENSO_predictability.cm3_nino34_c1.nc')\n",
    "else:\n",
    "    cm3_nino34_c1 = xr.open_dataset(dataloc + 'ENSO_predictability.cm3_nino34_c1.nc')['c1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c2 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "\n",
    "    clim = cm3_nino34_full.sel(init_date=clim_period).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    cm3_nino34_c2 = (cm3_nino34_full.groupby('init_date.month') - clim).rename('c2')\n",
    "    \n",
    "    cm3_nino34_c2.to_netcdf(dataloc + 'ENSO_predictability.cm3_nino34_c2.nc')\n",
    "else:\n",
    "    cm3_nino34_c2 = xr.open_dataset(dataloc + 'ENSO_predictability.cm3_nino34_c2.nc')['c2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c3 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    \n",
    "    init_dates = cm3_nino34_c0.sel(init_date=clim_period).init_date.copy()\n",
    "    lead_times = cm3_nino34_c0.sel(init_date=clim_period).lead_time.copy()\n",
    "    init_dates.values = np.arange(len(init_dates))\n",
    "    mask = (init_dates + lead_times) <= init_dates[-1]\n",
    "\n",
    "    fcst_er = (cm3_nino34_c0.where(mask) - obs_2_use['c0'].where(mask)).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    \n",
    "    cm3_nino34_c3 = (cm3_nino34_c0.groupby('init_date.month') - fcst_er).rename('c3')\n",
    "\n",
    "    cm3_nino34_c3.to_netcdf(dataloc + 'ENSO_predictability.cm3_nino34_c3.nc')\n",
    "else:\n",
    "    cm3_nino34_c3 = xr.open_dataset(dataloc + 'ENSO_predictability.cm3_nino34_c3.nc')['c3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 full anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','2015')\n",
    "    cm3_nino34_full_use = cm3_nino34_full.sel(init_date=clim_period).mean('ensemble')\n",
    "    cm3_nino34_c1full = cm3_nino34_full.groupby('init_date').apply(cv_anomalize, clim_ts=cm3_nino34_full_use).rename('c1full')\n",
    "    \n",
    "    cm3_nino34_c1full.to_netcdf(dataloc + 'ENSO_predictability.cm3_nino34_c1full.nc')\n",
    "else:\n",
    "    cm3_nino34_c1full = xr.open_dataset(dataloc + 'ENSO_predictability.cm3_nino34_c1full.nc')['c1full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 ncv anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1999','2015')\n",
    "\n",
    "    clim = cm3_nino34_full.sel(init_date=clim_period).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    cm3_nino34_c1ncv = (cm3_nino34_full.groupby('init_date.month') - clim).rename('c1ncv')\n",
    "    \n",
    "    cm3_nino34_c1ncv.to_netcdf(dataloc + 'ENSO_predictability.cm3_nino34_c1ncv.nc')\n",
    "else:\n",
    "    cm3_nino34_c1ncv = xr.open_dataset(dataloc + 'ENSO_predictability.cm3_nino34_c1ncv.nc')['c1ncv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm3_nino34 = cm3_nino34_full.to_dataset()\n",
    "cm3_nino34['c0'] = cm3_nino34_c0\n",
    "cm3_nino34['c1'] = cm3_nino34_c1\n",
    "cm3_nino34['c2'] = cm3_nino34_c2\n",
    "cm3_nino34['c3'] = cm3_nino34_c3\n",
    "cm3_nino34['c1full'] = cm3_nino34_c1full\n",
    "cm3_nino34['c1ncv'] = cm3_nino34_c1ncv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw CMC CanCM4 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    folder = '/OSM/CBR/OA_DCFP/data2/model_output/NMME/phase1/CMC_CanCM4/monthly/'\n",
    "    hcstfiles = 'sst_mon_CanCM4_198101*.nc'\n",
    "    fcstfiles = 'sst_mon_CanCM4_201101*.nc'\n",
    "\n",
    "    hcstlist = glob.glob(folder + hcstfiles)\n",
    "    hcstlist.sort(key=natural_keys)\n",
    "    fcstlist = glob.glob(folder + fcstfiles)\n",
    "    fcstlist.sort(key=natural_keys)\n",
    "\n",
    "    cm4_sst_raw = xr.concat([xr.open_mfdataset(hcstlist, decode_times=False)['sst'] - 273.15,\n",
    "                             xr.open_mfdataset(fcstlist, decode_times=False)['sst'] - 273.15], dim='S') \\\n",
    "                    .rename({'X' : 'lon', 'Y' : 'lat', 'M' : 'ensemble', \n",
    "                             'L' : 'lead_time', 'S' : 'init_date'}).compute()\n",
    "\n",
    "    basedate = np.datetime64(cm4_sst_raw.init_date.units.split(' ')[2])\n",
    "    cm4_sst_raw['init_date'] = np.array([doppyo.sugar.month_delta(basedate, int(shift)) for shift in cm4_sst_raw.init_date.values])\n",
    "\n",
    "    cm4_sst_raw['lead_time'] = [int(lead_time - 0.5) for lead_time in cm4_sst_raw['lead_time']]\n",
    "    cm4_sst_raw.lead_time.attrs['units'] = 'MS'\n",
    "\n",
    "    cm4_sst_raw['ensemble'] = [int(ensemble) for ensemble in cm4_sst_raw['ensemble']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute nino3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    cm4_nino34_full = doppyo.diagnostic.nino34(cm4_sst_raw).rename('full')\n",
    "\n",
    "    cm4_nino34_full.to_netcdf(dataloc + 'ENSO_predictability.cm4_nino34_full.nc')\n",
    "else:\n",
    "    cm4_nino34_full = xr.open_dataset(dataloc + 'ENSO_predictability.cm4_nino34_full.nc')['full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c0 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    clim = obs_2_use['full'].sel(init_date=clim_period, lead_time=0).groupby('init_date.month').mean('init_date').drop('lead_time')\n",
    "    cm4_nino34_c0 = cm4_nino34_full.groupby('init_date').apply(lambda_anomalize, clim=clim).rename('c0')\n",
    "    \n",
    "    cm4_nino34_c0.to_netcdf(dataloc + 'ENSO_predictability.cm4_nino34_c0.nc')\n",
    "else:\n",
    "    cm4_nino34_c0 = xr.open_dataset(dataloc + 'ENSO_predictability.cm4_nino34_c0.nc')['c0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1999','2015')\n",
    "    cm4_nino34_full_use = cm4_nino34_full.sel(init_date=clim_period).mean('ensemble')\n",
    "    cm4_nino34_c1 = cm4_nino34_full.groupby('init_date').apply(cv_anomalize, clim_ts=cm4_nino34_full_use).rename('c1')\n",
    "    \n",
    "    cm4_nino34_c1.to_netcdf(dataloc + 'ENSO_predictability.cm4_nino34_c1.nc')\n",
    "else:\n",
    "    cm4_nino34_c1 = xr.open_dataset(dataloc + 'ENSO_predictability.cm4_nino34_c1.nc')['c1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c2 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "\n",
    "    clim = cm4_nino34_full.sel(init_date=clim_period).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    cm4_nino34_c2 = (cm4_nino34_full.groupby('init_date.month') - clim).rename('c2')\n",
    "    \n",
    "    cm4_nino34_c2.to_netcdf(dataloc + 'ENSO_predictability.cm4_nino34_c2.nc')\n",
    "else:\n",
    "    cm4_nino34_c2 = xr.open_dataset(dataloc + 'ENSO_predictability.cm4_nino34_c2.nc')['c2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c3 anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','1998')\n",
    "    \n",
    "    init_dates = cm4_nino34_c0.sel(init_date=clim_period).init_date.copy()\n",
    "    lead_times = cm4_nino34_c0.sel(init_date=clim_period).lead_time.copy()\n",
    "    init_dates.values = np.arange(len(init_dates))\n",
    "    mask = (init_dates + lead_times) <= init_dates[-1]\n",
    "\n",
    "    fcst_er = (cm4_nino34_c0.where(mask) - obs_2_use['c0'].where(mask)).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    \n",
    "    cm4_nino34_c3 = (cm4_nino34_c0.groupby('init_date.month') - fcst_er).rename('c3')\n",
    "\n",
    "    cm4_nino34_c3.to_netcdf(dataloc + 'ENSO_predictability.cm4_nino34_c3.nc')\n",
    "else:\n",
    "    cm4_nino34_c3 = xr.open_dataset(dataloc + 'ENSO_predictability.cm4_nino34_c3.nc')['c3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 full anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1982','2015')\n",
    "    cm4_nino34_full_use = cm4_nino34_full.sel(init_date=clim_period).mean('ensemble')\n",
    "    cm4_nino34_c1full = cm4_nino34_full.groupby('init_date').apply(cv_anomalize, clim_ts=cm4_nino34_full_use).rename('c1full')\n",
    "    \n",
    "    cm4_nino34_c1full.to_netcdf(dataloc + 'ENSO_predictability.cm4_nino34_c1full.nc')\n",
    "else:\n",
    "    cm4_nino34_c1full = xr.open_dataset(dataloc + 'ENSO_predictability.cm4_nino34_c1full.nc')['c1full']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 ncv anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_data:\n",
    "    clim_period = slice('1999','2015')\n",
    "\n",
    "    clim = cm4_nino34_full.sel(init_date=clim_period).groupby('init_date.month').mean(['init_date','ensemble'])\n",
    "    cm4_nino34_c1ncv = (cm4_nino34_full.groupby('init_date.month') - clim).rename('c1ncv')\n",
    "    \n",
    "    cm4_nino34_c1ncv.to_netcdf(dataloc + 'ENSO_predictability.cm4_nino34_c1ncv.nc')\n",
    "else:\n",
    "    cm4_nino34_c1ncv = xr.open_dataset(dataloc + 'ENSO_predictability.cm4_nino34_c1ncv.nc')['c1ncv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm4_nino34 = cm4_nino34_full.to_dataset()\n",
    "cm4_nino34['c0'] = cm4_nino34_c0\n",
    "cm4_nino34['c1'] = cm4_nino34_c1\n",
    "cm4_nino34['c2'] = cm4_nino34_c2\n",
    "cm4_nino34['c3'] = cm4_nino34_c3\n",
    "cm4_nino34['c1full'] = cm4_nino34_c1full\n",
    "cm4_nino34['c1ncv'] = cm4_nino34_c1ncv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-model mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmm_nino34 = xr.concat([cola_nino34, aer04_nino34, florA_nino34, florB_nino34, cm3_nino34, cm4_nino34], dim='ensemble').mean('ensemble')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary linear regression model\n",
    "For each of c0, c1, c2 and c3, the linear regression model is compute in a way consistent with how the observed anomalies are computed:\n",
    "\n",
    "**c0** : the regression model is trained on observed c0 anomalies over the period **1982-01 -> 1998-12** and apply over **1999-01 -> 2015-12**\n",
    "\n",
    "**c1** : the regression model is trained on observed c1 anomalies over the period **1999-01 -> 2015-12** using a cross-validation approach and then applied over the same period\n",
    "\n",
    "**c2** : the regression model is trained on observed c2 anomalies (same as c1) over the period **1982-01 -> 1998-12** and apply over **1999-01 -> 2015-12**\n",
    "\n",
    "**c1full** : the regression model is trained on observed c1 anomalies over the period **1982-01 -> 2015-12** using a cross-validation approach and then applied over the same period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c0 regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_period = slice('1982','1998')\n",
    "predict_period = slice('1999','2015')\n",
    "regr_nino34_c0 = Delsole_regression(obs_2_use['c0'].sel(init_date=predict_period, lead_time=0),\n",
    "                                    obs_2_use['c0'].sel(init_date=train_period)).rename('c0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_period = slice('1999','2015')\n",
    "predict_period = slice('1999','2015')\n",
    "regr_nino34_c1 = obs_2_use['c1'].sel(init_date=predict_period).sel(lead_time=0,drop=True).groupby('init_date') \\\n",
    "                                 .apply(Delsole_regression, da_train=obs_2_use['c1'].sel(init_date=train_period)).rename('c1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c2 regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_nino34_c2 = regr_nino34_c0.rename('c2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c3 regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_nino34_c3 = regr_nino34_c0.rename('c3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c1 full regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_period = slice('1982','2015')\n",
    "predict_period = slice('1982','2015')\n",
    "regr_nino34_c1full = obs_2_use['c1full'].sel(init_date=predict_period).sel(lead_time=0,drop=True).groupby('init_date') \\\n",
    "                                 .apply(Delsole_regression, da_train=obs_2_use['c1full'].sel(init_date=train_period)).rename('c1full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_nino34 = regr_nino34_c0.to_dataset()\n",
    "regr_nino34['c1'] = regr_nino34_c1\n",
    "regr_nino34['c2'] = regr_nino34_c2\n",
    "regr_nino34['c3'] = regr_nino34_c3\n",
    "regr_nino34['c1full'] = regr_nino34_c1full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ENSO events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_elnino = obs_2_use.apply(where_elninos).drop('full')\n",
    "where_lanina = obs_2_use.apply(where_laninas).drop('full')\n",
    "\n",
    "where_elnino_cola = cola_nino34.mean('ensemble').apply(where_elninos).drop('full')\n",
    "where_lanina_cola = cola_nino34.mean('ensemble').apply(where_laninas).drop('full')\n",
    "\n",
    "where_elnino_aer04 = aer04_nino34.mean('ensemble').apply(where_elninos).drop('full')\n",
    "where_lanina_aer04 = aer04_nino34.mean('ensemble').apply(where_laninas).drop('full')\n",
    "\n",
    "where_elnino_florA = florA_nino34.mean('ensemble').apply(where_elninos).drop('full')\n",
    "where_lanina_florA = florA_nino34.mean('ensemble').apply(where_laninas).drop('full')\n",
    "\n",
    "where_elnino_florB = florB_nino34.mean('ensemble').apply(where_elninos).drop('full')\n",
    "where_lanina_florB = florB_nino34.mean('ensemble').apply(where_laninas).drop('full')\n",
    "\n",
    "where_elnino_cm3 = cm3_nino34.mean('ensemble').apply(where_elninos).drop('full')\n",
    "where_lanina_cm3 = cm3_nino34.mean('ensemble').apply(where_laninas).drop('full')\n",
    "\n",
    "where_elnino_cm4 = cm4_nino34.mean('ensemble').apply(where_elninos).drop('full')\n",
    "where_lanina_cm4 = cm4_nino34.mean('ensemble').apply(where_laninas).drop('full')\n",
    "\n",
    "where_elnino_regr = regr_nino34.apply(where_elninos)\n",
    "where_lanina_regr = regr_nino34.apply(where_laninas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linewidth = 2\n",
    "fontsize = 12\n",
    "grey = [0.9,0.9,0.9]\n",
    "\n",
    "matplotlib.rc('font', family='sans-serif') \n",
    "matplotlib.rc('font', serif='Helvetica') \n",
    "matplotlib.rc('text', usetex='false') \n",
    "matplotlib.rcParams.update({'font.size': fontsize})\n",
    "\n",
    "anom='c2'\n",
    "figure = plt.figure(figsize=(12,6))\n",
    "fcst_dates = pd.date_range(start='2006-01', end='2013-01', freq='MS')[::-1]\n",
    "    \n",
    "for idx, date in enumerate(fcst_dates):\n",
    "    if idx == 0:\n",
    "        plot_fcst(doppyo.utils.leadtime_to_datetime(mmm_nino34[anom].sel(init_date=date)).time,\n",
    "                  doppyo.utils.leadtime_to_datetime(mmm_nino34[anom].sel(init_date=date)), cmap='winter', \n",
    "                  **{'linewidth':linewidth,'label':'NMME multi-model ensemble average'})\n",
    "    else:\n",
    "        plot_fcst(doppyo.utils.leadtime_to_datetime(mmm_nino34[anom].sel(init_date=date)).time,\n",
    "                  doppyo.utils.leadtime_to_datetime(mmm_nino34[anom].sel(init_date=date)), cmap='winter', \n",
    "                  **{'linewidth':linewidth,'label':'_nolegend_'})\n",
    "    \n",
    "for idx, date in enumerate(fcst_dates):\n",
    "    if idx == 0:\n",
    "        plot_fcst(doppyo.utils.leadtime_to_datetime(regr_nino34[anom].sel(init_date=date)).time,\n",
    "                  doppyo.utils.leadtime_to_datetime(regr_nino34[anom].sel(init_date=date)), cmap='autumn', \n",
    "                  **{'linewidth':linewidth,'label':'Linear regression'})\n",
    "    else:\n",
    "        plot_fcst(doppyo.utils.leadtime_to_datetime(regr_nino34[anom].sel(init_date=date)).time,\n",
    "                  doppyo.utils.leadtime_to_datetime(regr_nino34[anom].sel(init_date=date)), cmap='autumn', \n",
    "                  **{'linewidth':linewidth,'label':'_nolegend_'})\n",
    "\n",
    "for idx, date in enumerate(fcst_dates):\n",
    "    if idx == 0:\n",
    "        plt.plot(doppyo.utils.leadtime_to_datetime(cola_nino34[anom].sel(init_date=date)).time.values,\n",
    "                 doppyo.utils.leadtime_to_datetime(cola_nino34[anom].sel(init_date=date)).mean('ensemble'),\n",
    "                 color=grey, zorder=1, label='NMME individual model ensemble average', linewidth=linewidth)\n",
    "    else:\n",
    "        plt.plot(doppyo.utils.leadtime_to_datetime(cola_nino34[anom].sel(init_date=date)).time.values,\n",
    "                 doppyo.utils.leadtime_to_datetime(cola_nino34[anom].sel(init_date=date)).mean('ensemble'), \n",
    "                 color=grey, zorder=1, label='_nolegend_', linewidth=linewidth)\n",
    "for date in fcst_dates:\n",
    "    plt.plot(doppyo.utils.leadtime_to_datetime(aer04_nino34[anom].sel(init_date=date)).time.values,\n",
    "                 doppyo.utils.leadtime_to_datetime(aer04_nino34[anom].sel(init_date=date)).mean('ensemble'), \n",
    "                 color=grey, zorder=1, label='_nolegend_', linewidth=linewidth)\n",
    "for date in fcst_dates:\n",
    "    plt.plot(doppyo.utils.leadtime_to_datetime(florA_nino34[anom].sel(init_date=date)).time.values,\n",
    "                 doppyo.utils.leadtime_to_datetime(florA_nino34[anom].sel(init_date=date)).mean('ensemble'), \n",
    "                 color=grey, zorder=1, label='_nolegend_', linewidth=linewidth)\n",
    "for date in fcst_dates:\n",
    "    plt.plot(doppyo.utils.leadtime_to_datetime(florB_nino34[anom].sel(init_date=date)).time.values,\n",
    "                 doppyo.utils.leadtime_to_datetime(florB_nino34[anom].sel(init_date=date)).mean('ensemble'), \n",
    "                 color=grey, zorder=1, label='_nolegend_', linewidth=linewidth)\n",
    "for date in fcst_dates:\n",
    "    plt.plot(doppyo.utils.leadtime_to_datetime(cm3_nino34[anom].sel(init_date=date)).time.values,\n",
    "                 doppyo.utils.leadtime_to_datetime(cm3_nino34[anom].sel(init_date=date)).mean('ensemble'), \n",
    "                 color=grey, zorder=1, label='_nolegend_', linewidth=linewidth)\n",
    "for date in fcst_dates:\n",
    "    plt.plot(doppyo.utils.leadtime_to_datetime(cm4_nino34[anom].sel(init_date=date)).time.values,\n",
    "                 doppyo.utils.leadtime_to_datetime(cm4_nino34[anom].sel(init_date=date)).mean('ensemble'), \n",
    "                 color=grey, zorder=1, label='_nolegend_', linewidth=linewidth)\n",
    "\n",
    "# for idx, date in enumerate(fcst_dates):\n",
    "#     plt.plot(doppyo.utils.leadtime_to_datetime(fcst_use.sel(init_date=date)).time.values,\n",
    "#              doppyo.utils.leadtime_to_datetime(fcst_use.sel(init_date=date)), color=(0.95,0.95,0.95), zorder=0, label='_nolegend_')\n",
    "\n",
    "obs_2_use[anom].sel(lead_time=0).plot(color='k', linestyle='-', linewidth=linewidth+1, label='Observations')\n",
    "\n",
    "plt.xlim('2007','2013')\n",
    "plt.ylim(-3.8,3.8);\n",
    "plt.xlabel('time');\n",
    "plt.ylabel('NINO-3.4');\n",
    "plt.title('')\n",
    "\n",
    "# Make the legend -----\n",
    "span = pd.date_range('2007-02-01','2007-05-01', freq='15D')\n",
    "plt.plot(span, 3.5*np.ones_like(span.astype(int)), color=grey, zorder=1, linewidth=linewidth)\n",
    "plt.text('2007-05-25', 3.4, 'NMME individual model ensemble average', fontsize=fontsize-1)\n",
    "plot_fcst(span, 3.15*np.ones_like(span.astype(int)), cmap='winter', **{'linewidth':linewidth})\n",
    "plt.text('2007-05-25', 3.05, 'NMME multi-model ensemble average', fontsize=fontsize-1)\n",
    "plot_fcst(span, 2.8*np.ones_like(span.astype(int)), cmap='autumn', **{'linewidth':linewidth})\n",
    "plt.text('2007-05-25', 2.7, 'Linear regression', fontsize=fontsize-1)\n",
    "plt.plot(span, 2.45*np.ones_like(span.astype(int)), color='k', linestyle='-', linewidth=linewidth+1)\n",
    "plt.text('2007-05-25', 2.35, 'Observations', fontsize=fontsize-1)\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do the different anomalies compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead=11\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "cola_nino34['c0'].sel(lead_time=lead).mean('ensemble').plot(linestyle='-', color='#1f77b4', label='_nolegend_')\n",
    "cola_nino34['c1'].sel(lead_time=lead).mean('ensemble').plot(linestyle='--', color='#1f77b4', label='_nolegend_')\n",
    "cola_nino34['c2'].sel(lead_time=lead).mean('ensemble').plot(linestyle='-.', color='#1f77b4', label='_nolegend_')\n",
    "\n",
    "# aer04_nino34['c0'].sel(lead_time=lead).mean('ensemble').plot(linestyle='-', color='#ff7f0e', label='_nolegend_')\n",
    "# aer04_nino34['c1'].sel(lead_time=lead).mean('ensemble').plot(linestyle='--', color='#ff7f0e', label='_nolegend_')\n",
    "# aer04_nino34['c2'].sel(lead_time=lead).mean('ensemble').plot(linestyle='-.', color='#ff7f0e', label='_nolegend_')\n",
    "\n",
    "# florA_nino34['c0'].sel(lead_time=lead).mean('ensemble').plot(linestyle='-', color='#2ca02c', label='_nolegend_')\n",
    "# florA_nino34['c1'].sel(lead_time=lead).mean('ensemble').plot(linestyle='--', color='#2ca02c', label='_nolegend_')\n",
    "# florA_nino34['c2'].sel(lead_time=lead).mean('ensemble').plot(linestyle='-.', color='#2ca02c', label='_nolegend_')\n",
    "\n",
    "# florB_nino34['c0'].sel(lead_time=lead).mean('ensemble').plot(linestyle='-', color='#d62728', label='_nolegend_')\n",
    "# florB_nino34['c1'].sel(lead_time=lead).mean('ensemble').plot(linestyle='--', color='#d62728', label='_nolegend_')\n",
    "# florB_nino34['c2'].sel(lead_time=lead).mean('ensemble').plot(linestyle='-.', color='#d62728', label='_nolegend_')\n",
    "\n",
    "# cm3_nino34['c0'].sel(lead_time=lead).mean('ensemble').plot(linestyle='-', color='#9467bd', label='_nolegend_')\n",
    "# cm3_nino34['c1'].sel(lead_time=lead).mean('ensemble').plot(linestyle='--', color='#9467bd', label='_nolegend_')\n",
    "# cm3_nino34['c2'].sel(lead_time=lead).mean('ensemble').plot(linestyle='-.', color='#9467bd', label='_nolegend_')\n",
    "\n",
    "# cm4_nino34['c0'].sel(lead_time=lead).mean('ensemble').plot(linestyle='-', color='#8c564b', label='_nolegend_')\n",
    "# cm4_nino34['c1'].sel(lead_time=lead).mean('ensemble').plot(linestyle='--', color='#8c564b', label='_nolegend_')\n",
    "# cm4_nino34['c2'].sel(lead_time=lead).mean('ensemble').plot(linestyle='-.', color='#8c564b', label='_nolegend_')\n",
    "\n",
    "obs_2_use['c0'].sel(lead_time=lead).plot(linestyle='-', color='k', label='c0')\n",
    "obs_2_use['c1'].sel(lead_time=lead).plot(linestyle='--', color='k', label='c1')\n",
    "obs_2_use['c2'].sel(lead_time=lead).plot(linestyle='-.', color='k', label='c2')\n",
    "\n",
    "plt.fill_between(where_elnino['c0'].init_date.values, -5, (100*where_elnino['c0'].sel(lead_time=lead)-10), color='red', alpha=0.1, edgecolor=None)\n",
    "plt.fill_between(where_lanina['c0'].init_date.values, -5, (100*where_lanina['c0'].sel(lead_time=lead)-10), color='blue', alpha=0.1, edgecolor=None)\n",
    "# plt.fill_between(where_elnino['c1'].init_date.values, -5, (100*where_elnino['c1'].sel(lead_time=lead)-10), color='magenta', alpha=0.1, edgecolor=None)\n",
    "# plt.fill_between(where_lanina['c1'].init_date.values, -5, (100*where_lanina['c1'].sel(lead_time=lead)-10), color='purple', alpha=0.1, edgecolor=None)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim(-4,4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, let's get an appreciation of the NMME skill by looking at contingency tables for El Nino and La Nina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_state = where_lanina.where(where_lanina == 0, other=-1) + where_elnino.where(where_elnino == 0, other=1)\n",
    "\n",
    "which_state_cola = where_lanina_cola.where(where_lanina_cola == 0, other=-1) + where_elnino_cola.where(where_elnino_cola == 0, other=1)\n",
    "which_state_aer04 = where_lanina_aer04.where(where_lanina_aer04 == 0, other=-1) + where_elnino_aer04.where(where_elnino_aer04 == 0, other=1)\n",
    "which_state_florA = where_lanina_florA.where(where_lanina_florA == 0, other=-1) + where_elnino_florA.where(where_elnino_florA == 0, other=1)\n",
    "which_state_florB = where_lanina_florB.where(where_lanina_florB == 0, other=-1) + where_elnino_florB.where(where_elnino_florB == 0, other=1)\n",
    "which_state_cm3 = where_lanina_cm3.where(where_lanina_cm3 == 0, other=-1) + where_elnino_cm3.where(where_elnino_cm3 == 0, other=1)\n",
    "which_state_cm4 = where_lanina_cm4.where(where_lanina_cm4 == 0, other=-1) + where_elnino_cm4.where(where_elnino_cm4 == 0, other=1)\n",
    "\n",
    "which_state_regr = where_lanina_regr.where(where_lanina_regr == 0, other=-1) + where_elnino_regr.where(where_elnino_regr == 0, other=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms = ['c0','c1','c2']\n",
    "time_period = slice('1999','2015')\n",
    "\n",
    "fig = plt.figure(figsize=(5*len(anoms),9))\n",
    "axes = fig.subplots(3, ncols=len(anoms), sharex=True, sharey=True)\n",
    "Gerrity = []\n",
    "for idx, anom in enumerate(anoms):\n",
    "    \n",
    "    da_cmp = which_state_cm4[anom].sel(init_date=time_period)\n",
    "    da_ref = which_state[anom].sel(init_date=time_period)\n",
    "    edge = [-np.inf, -0.5, 0.5, np.inf]\n",
    "    contingency = doppyo.skill.contingency(da_cmp, da_ref, edge, edge, over_dims='init_date')\n",
    "    \n",
    "    Gerrity.append(doppyo.skill.Gerrity_score(contingency))\n",
    "    \n",
    "    for idy in range(3):\n",
    "        ax = axes[idy, idx]\n",
    "    \n",
    "        if idy == 0:\n",
    "            total = contingency.sel(reference_category=1).sum('comparison_category')\n",
    "            (contingency.sel(reference_category=1, comparison_category=1) / total).plot(ax=ax, color='b', linestyle='-', label='La Nina - La Nina')\n",
    "            (contingency.sel(reference_category=1, comparison_category=2) / total).plot(ax=ax, color='b', linestyle='--', label='La Nina - Neutral')\n",
    "            (contingency.sel(reference_category=1, comparison_category=3) / total).plot(ax=ax, color='b', linestyle=':', label='La Nina - El Nino')\n",
    "\n",
    "        elif idy == 1:\n",
    "            total = contingency.sel(reference_category=2).sum('comparison_category')\n",
    "            (contingency.sel(reference_category=2, comparison_category=1) / total).plot(ax=ax, color='k', linestyle='--', label='Neutral - La Nina')\n",
    "            (contingency.sel(reference_category=2, comparison_category=2) / total).plot(ax=ax, color='k', linestyle='-', label='Neutral - Neutral')\n",
    "            (contingency.sel(reference_category=2, comparison_category=3) / total).plot(ax=ax, color='k', linestyle=':', label='Neutral - El Nino')\n",
    "\n",
    "        elif idy == 2:\n",
    "            total = contingency.sel(reference_category=3).sum('comparison_category')\n",
    "            (contingency.sel(reference_category=3, comparison_category=1) / total).plot(ax=ax, color='r', linestyle='--', label='El Nino - La Nina')\n",
    "            (contingency.sel(reference_category=3, comparison_category=2) / total).plot(ax=ax, color='r', linestyle=':', label='El Nino - Neutral')\n",
    "            (contingency.sel(reference_category=3, comparison_category=3) / total).plot(ax=ax, color='r', linestyle='-', label='El Nino - El Nino')\n",
    "    \n",
    "        ax.set_title('')\n",
    "        if idx != 0:\n",
    "            ax.set_ylabel('')\n",
    "        if idy != 2:\n",
    "            ax.set_xlabel('')\n",
    "        if idx == 0:\n",
    "            ax.legend()\n",
    "    ax.set_ylim(-0.1,1.1)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maybe this isn't the most intuitive way to present absolute skill. What about the Gerrity score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [which_state_cola, which_state_aer04, which_state_florA, which_state_florB, which_state_cm3, which_state_cm4, which_state_regr]\n",
    "\n",
    "anoms = ['c0','c1','c2']\n",
    "fig = plt.figure(figsize=(5*len(anoms),3*1))\n",
    "axes = fig.subplots(nrows=1, ncols=len(anoms), sharex=True)\n",
    "\n",
    "for idy, anom in enumerate(anoms):\n",
    "    for idx, model in enumerate(models):\n",
    "        ax = axes[idy]\n",
    "        da_cmp = model[anom].sel(init_date=time_period)\n",
    "        da_ref = which_state[anom].sel(init_date=time_period)\n",
    "        edge = [-np.inf, -0.5, 0.5, np.inf]\n",
    "        contingency = doppyo.skill.contingency(da_cmp, da_ref, edge, edge, over_dims='init_date')\n",
    "\n",
    "        doppyo.skill.Gerrity_score(contingency).plot(ax=ax)\n",
    "    \n",
    "        ax.set_ylim(0,1);\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Still not entirely intuitive. What about mean squared skill score (MSSS) and anomaly cross correlation (ACC)?\n",
    "Focus on **c3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linewidth = 2\n",
    "fontsize = 12\n",
    "\n",
    "matplotlib.rc('font', family='sans-serif') \n",
    "matplotlib.rc('font', serif='Helvetica') \n",
    "matplotlib.rc('text', usetex='false') \n",
    "matplotlib.rcParams.update({'font.size': fontsize})\n",
    "\n",
    "anom = 'c2'\n",
    "models = [cola_nino34.mean('ensemble'), aer04_nino34.mean('ensemble'), florA_nino34.mean('ensemble'), \n",
    "          florB_nino34.mean('ensemble'), cm3_nino34.mean('ensemble'), cm4_nino34.mean('ensemble'), regr_nino34]\n",
    "model_name = ['cola','aer04','florA','florB','cm3','cm4','linear regression']\n",
    "\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "axes = fig.subplots(nrows=1, ncols=2, sharex=True)\n",
    "for idx, model in enumerate(models):\n",
    "    ax0 = axes[0]\n",
    "    MSE_f = doppyo.skill.mean_squared_error(model[anom], obs_2_use[anom], over_dims='init_date')\n",
    "    MSE_o = doppyo.skill.mean_squared_error(0*obs_2_use[anom], obs_2_use[anom], over_dims='init_date')\n",
    "    ax0.plot([-1,12],[0,0],'-',color=[0.85,0.85,0.85], zorder=0)\n",
    "    (1 - MSE_f / MSE_o).plot(ax=ax0, label=model_name[idx], linewidth=linewidth, color=colors[idx])\n",
    "    legend = ax0.legend(ncol=2, fontsize=fontsize-1)\n",
    "    legend.get_frame().set_facecolor('w')\n",
    "    legend.get_frame().set_edgecolor('w')\n",
    "    ax0.set_xlim(0,11)\n",
    "    ax0.set_ylim(-1,1)\n",
    "    ax0.set_ylabel('MSSS')\n",
    "    ax0.set_xlabel('lead [months]')\n",
    "\n",
    "    ax1 = axes[1]\n",
    "    ACC = doppyo.skill.Pearson_corrcoeff(model[anom], obs_2_use[anom], over_dims='init_date')\n",
    "    ax1.plot([-1,12],[0,0],'-',color=[0.85,0.85,0.85], zorder=0)\n",
    "    ACC.plot(ax=ax1, label=model_name[idx], linewidth=linewidth, color=colors[idx])\n",
    "    ax1.set_ylim(-1,1)\n",
    "    ax1.set_ylabel('ACC')\n",
    "    ax1.set_xlabel('lead [months]')\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the (sign test) skill relative to linear regression for each of the different anomaly types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead = 2\n",
    "anoms = ['c0','c1','c2','c3']\n",
    "masks = [1 + 0*where_elnino]\n",
    "models = [cola_nino34, aer04_nino34, florA_nino34, florB_nino34, cm3_nino34, cm4_nino34]\n",
    "model_name = ['cola','aer04','florA','florB','cm3','cm4']\n",
    "\n",
    "fig = plt.figure(figsize=(5*len(anoms),3*len(masks)))\n",
    "axes = fig.subplots(nrows=len(masks), ncols=len(anoms), sharex=True)\n",
    "for idx, anom in enumerate(anoms):\n",
    "    for idy, mask in enumerate(masks):\n",
    "        if len(anoms) == 1:\n",
    "            ax = axes[idy]\n",
    "        elif len(masks) == 1:\n",
    "            ax = axes[idx]\n",
    "        else:\n",
    "            ax = axes[idy, idx]\n",
    "        for idz, model in enumerate(models):\n",
    "            sign, conf = doppyo.skill.sign_test(regr_nino34[anom].where(mask[anom]), \n",
    "                                                model[anom].mean('ensemble').where(mask[anom]), \n",
    "                                                obs_2_use[anom].sel(init_date=slice('1999','2015')).where(mask[anom]))\n",
    "                \n",
    "            if idz == 0:\n",
    "                ax.fill_between(conf.init_date.values,\n",
    "                                -1 * conf.sel(lead_time=lead), \n",
    "                                conf.sel(lead_time=lead), color='gray', alpha=0.2, label='_nolegend_')\n",
    "            ax.plot(sign.init_date, sign.sel(lead_time=lead), label=model_name[idz])\n",
    "            \n",
    "        if (idx == 0) & (idy == 0):\n",
    "            ax.legend()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the area under the curves as a function of lead time\n",
    "Note that when computing the areas, it is important to only include points where the sign_test had the opportunity to change - ie. when supplying masks to the sign_test, the ssame amsks put also be applied before the integral is calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms = ['c0','c1','c2','c3']\n",
    "masks = [1 + 0*where_elnino]\n",
    "models = [cola_nino34, aer04_nino34, florA_nino34, florB_nino34, cm3_nino34, cm4_nino34]\n",
    "model_name = ['cola','aer04','florA','florB','cm3','cm4']\n",
    "\n",
    "fig = plt.figure(figsize=(5*len(anoms),3*len(masks)))\n",
    "axes = fig.subplots(nrows=len(masks), ncols=len(anoms), sharex=True)\n",
    "for idx, anom in enumerate(anoms):\n",
    "    for idy, mask in enumerate(masks):\n",
    "        if len(anoms) == 1:\n",
    "            ax = axes[idy]\n",
    "        elif len(masks) == 1:\n",
    "            ax = axes[idx]\n",
    "        else:\n",
    "            ax = axes[idy, idx]\n",
    "        for idz, model in enumerate(models):\n",
    "            sign_test = doppyo.skill.sign_test(regr_nino34[anom].where(mask[anom]), \n",
    "                                               model[anom].mean('ensemble').where(mask[anom]), \n",
    "                                               obs_2_use[anom].sel(init_date=slice('1999','2015')).where(mask[anom]))\n",
    "            \n",
    "            sign_masked = sign_test[0].where(mask[anom], drop=True)\n",
    "            conf_masked = sign_test[1].where(mask[anom], drop=True)\n",
    "            sign_area = doppyo.utils.integrate(sign_masked, over_dim='init_date', \n",
    "                                               x=(1+0*sign_masked.init_date.astype(int)).cumsum('init_date'), method='rect')\n",
    "            conf_area = doppyo.utils.integrate(conf_masked, over_dim='init_date', \n",
    "                                               x=(1+0*conf_masked.init_date.astype(int)).cumsum('init_date'), method='rect')\n",
    "            \n",
    "            if idz == 0:\n",
    "                ax.fill_between(conf_area.lead_time,\n",
    "                                -1 * conf_area, conf_area, color='gray', alpha=0.2, label='_nolegend_')\n",
    "            ax.plot(sign_area.lead_time, sign_area, label=model_name[idz])\n",
    "        if (idx == 0) & (idy == 0):\n",
    "            ax.legend()\n",
    "        \n",
    "        # Adjust y-axes limits to be symmetric -----\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        ylim = max([abs(ymin), abs(ymax)])\n",
    "        ax.set_ylim(-ylim, ylim)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linewidth = 2\n",
    "fontsize = 12\n",
    "matplotlib.rc('font', family='sans-serif') \n",
    "matplotlib.rc('font', serif='Helvetica') \n",
    "matplotlib.rc('text', usetex='false') \n",
    "matplotlib.rcParams.update({'font.size': fontsize})\n",
    "\n",
    "anoms = ['c2']\n",
    "masks = [1 + 0*where_elnino]\n",
    "models = [cola_nino34, aer04_nino34, florA_nino34, florB_nino34, cm3_nino34, cm4_nino34]\n",
    "model_name = ['cola','aer04','florA','florB','cm3','cm4']\n",
    "\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "axes = fig.subplots(nrows=len(masks), ncols=len(anoms), sharex=True)\n",
    "for idx, anom in enumerate(anoms):\n",
    "    for idy, mask in enumerate(masks):\n",
    "        if (len(anoms) == 1) & (len(masks) == 1):\n",
    "            ax = axes\n",
    "        elif len(anoms) == 1:\n",
    "            ax = axes[idy]\n",
    "        elif len(masks) == 1:\n",
    "            ax = axes[idx]\n",
    "        else:\n",
    "            ax = axes[idy, idx]\n",
    "        for idz, model in enumerate(models):\n",
    "            sign_test = doppyo.skill.sign_test(regr_nino34[anom].where(mask[anom]), \n",
    "                                               model[anom].mean('ensemble').where(mask[anom]), \n",
    "                                               obs_2_use[anom].sel(init_date=slice('1999','2015')).where(mask[anom]))\n",
    "            \n",
    "            sign_masked = sign_test[0].where(mask[anom], drop=True)\n",
    "            conf_masked = sign_test[1].where(mask[anom], drop=True)\n",
    "            sign_area = doppyo.utils.integrate(sign_masked, over_dim='init_date', \n",
    "                                               x=(1+0*sign_masked.init_date.astype(int)).cumsum('init_date'), method='rect')\n",
    "            conf_area = doppyo.utils.integrate(conf_masked, over_dim='init_date', \n",
    "                                               x=(1+0*conf_masked.init_date.astype(int)).cumsum('init_date'), method='rect')\n",
    "            \n",
    "            if idz == 0:\n",
    "                ax.plot(conf_area.lead_time + 0.5, conf_area, \n",
    "                        color='grey', alpha=0.3, linestyle='--', label='_nolabel_')\n",
    "                ax.plot(conf_area.lead_time + 0.5, -conf_area, \n",
    "                        color='grey', alpha=0.3, linestyle='--', label='_nolabel_')\n",
    "                ax.fill_between(conf_area.lead_time + 0.5, -1 * conf_area, conf_area, \n",
    "                                facecolor='grey', alpha=0.2, linewidth=0.0)\n",
    "            ax.plot(sign_area.lead_time + 0.5, sign_area, label=model_name[idz], linewidth=linewidth)\n",
    "            \n",
    "        if (idx == 0) & (idy == 0):\n",
    "            legend = ax.legend(ncol=2, fontsize=fontsize-1)\n",
    "            legend.get_frame().set_facecolor('w')\n",
    "            legend.get_frame().set_edgecolor('w')\n",
    "        \n",
    "        # Adjust y-axes limits to be symmetric -----\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        ylim = max([abs(ymin), abs(ymax)])\n",
    "        ax.set_ylim(-ylim, ylim)\n",
    "        ax.set_xlim(0,12)\n",
    "        ax.set_xlabel('lead [months]')\n",
    "        ax.set_ylabel('Area under sign test')\n",
    "        # ax.grid()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do the model **c1**, **c2** and **c1ncv** anomalies compare when assessed relative to observed **c2** anomalies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead = 6\n",
    "anoms = [('c1','c2'),('c1','c1ncv')]\n",
    "masks = [1 + 0*where_elnino]\n",
    "models = [cola_nino34, aer04_nino34, florA_nino34, florB_nino34, cm3_nino34, cm4_nino34]\n",
    "model_name = ['cola','aer04','florA','florB','cm3','cm4']\n",
    "\n",
    "fig = plt.figure(figsize=(5*len(anoms),3*len(masks)))\n",
    "axes = fig.subplots(nrows=len(masks), ncols=len(anoms), sharex=True)\n",
    "for idx, anom in enumerate(anoms):\n",
    "    for idy, mask in enumerate(masks):\n",
    "        if len(anoms) == 1:\n",
    "            ax = axes[idy]\n",
    "        elif len(masks) == 1:\n",
    "            ax = axes[idx]\n",
    "        else:\n",
    "            ax = axes[idy, idx]\n",
    "        for idz, model in enumerate(models):\n",
    "            sign, conf = doppyo.skill.sign_test(model[anom[0]].mean('ensemble').where(mask[anom[0]]), \n",
    "                                                model[anom[1]].mean('ensemble').where(mask[anom[1]]), \n",
    "                                                obs_2_use['c2'].sel(init_date=slice('1999','2015')).where(mask['c2']), scaled=False)\n",
    "            if idz == 0:\n",
    "                ax.fill_between(conf.init_date.values,\n",
    "                                -1 * conf.sel(lead_time=lead), \n",
    "                                conf.sel(lead_time=lead), color='gray', alpha=0.2, label='_nolegend_')\n",
    "            ax.plot(sign.init_date, sign.sel(lead_time=lead), label=model_name[idz])\n",
    "        if (idx == 0) & (idy == 0):\n",
    "            ax.legend()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms = [('c1','c3'),('c1','c1ncv')]\n",
    "masks = [1 + 0*where_elnino]\n",
    "models = [cola_nino34, aer04_nino34, florA_nino34, florB_nino34, cm3_nino34, cm4_nino34]\n",
    "model_name = ['cola','aer04','florA','florB','cm3','cm4']\n",
    "\n",
    "fig = plt.figure(figsize=(5*len(anoms),3*len(masks)))\n",
    "axes = fig.subplots(nrows=len(masks), ncols=len(anoms), sharex=True)\n",
    "for idx, anom in enumerate(anoms):\n",
    "    for idy, mask in enumerate(masks):\n",
    "        if len(anoms) == 1:\n",
    "            ax = axes[idy]\n",
    "        elif len(masks) == 1:\n",
    "            ax = axes[idx]\n",
    "        else:\n",
    "            ax = axes[idy, idx]\n",
    "        for idz, model in enumerate(models):\n",
    "            sign_test = doppyo.skill.sign_test(model[anom[0]].mean('ensemble').where(mask[anom[0]]), \n",
    "                                               model[anom[1]].mean('ensemble').where(mask[anom[1]]), \n",
    "                                               obs_2_use['c3'].sel(init_date=slice('1999','2015')).where(mask['c3']))\n",
    "            \n",
    "            sign_masked = sign_test[0].where(mask[anom[0]] & mask[anom[1]], drop=True)\n",
    "            conf_masked = sign_test[1].where(mask[anom[0]] & mask[anom[1]], drop=True)\n",
    "            sign_area = doppyo.utils.integrate(sign_masked, over_dim='init_date', \n",
    "                                               x=(1+0*sign_masked.init_date.astype(int)).cumsum('init_date'), method='rect')\n",
    "            conf_area = doppyo.utils.integrate(conf_masked, over_dim='init_date', \n",
    "                                               x=(1+0*conf_masked.init_date.astype(int)).cumsum('init_date'), method='rect')\n",
    "            \n",
    "            if idz == 0:\n",
    "                ax.fill_between(conf_area.lead_time,\n",
    "                                -1 * conf_area, conf_area, color='gray', alpha=0.2, label='_nolegend_')\n",
    "            ax.plot(sign_area.lead_time, sign_area, label=model_name[idz])\n",
    "        if (idx == 0) & (idy == 0):\n",
    "            ax.legend()\n",
    "        \n",
    "        # Adjust y-axes limits to be symmetric -----\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        ylim = max([abs(ymin), abs(ymax)])\n",
    "        ax.set_ylim(-ylim, ylim)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about **onset** of El Nino and La Nina?\n",
    "Here we assess, for each of El Nino and La Nina, forecasts which end in an event, but are **not** started in the same event\n",
    "\n",
    "In the first instance, observations are used to determine whether or not an event occurred. **This assesses the tendency of the forecasts to provide false negatives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_elnino_onset = where_elnino.apply(where_condition_events, method='onset')\n",
    "where_lanina_onset = where_lanina.apply(where_condition_events, method='onset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead = 6\n",
    "anoms = ['c0','c1','c2','c3']\n",
    "masks = [where_elnino_onset,\n",
    "         where_lanina_onset]\n",
    "models = [cola_nino34, aer04_nino34, florA_nino34, florB_nino34, cm3_nino34, cm4_nino34]\n",
    "model_name = ['cola','aer04','florA','florB','cm3','cm4']\n",
    "\n",
    "fig = plt.figure(figsize=(5*len(anoms),3*len(masks)))\n",
    "axes = fig.subplots(nrows=len(masks), ncols=len(anoms), sharex=True)\n",
    "for idx, anom in enumerate(anoms):\n",
    "    for idy, mask in enumerate(masks):\n",
    "        if len(anoms) == 1:\n",
    "            ax = axes[idy]\n",
    "        elif len(masks) == 1:\n",
    "            ax = axes[idx]\n",
    "        else:\n",
    "            ax = axes[idy, idx]\n",
    "        for idz, model in enumerate(models):\n",
    "            sign, conf = doppyo.skill.sign_test(regr_nino34[anom].where(mask[anom]), \n",
    "                                                model[anom].mean('ensemble').where(mask[anom]), \n",
    "                                                obs_2_use[anom].sel(init_date=slice('1999','2015')).where(mask[anom]))\n",
    "            \n",
    "            if idz == 0:\n",
    "                ax.fill_between(conf.init_date.values,\n",
    "                                -1 * conf.sel(lead_time=lead), \n",
    "                                conf.sel(lead_time=lead), color='gray', alpha=0.2, label='_nolegend_')\n",
    "            ax.plot(sign.init_date, sign.sel(lead_time=lead), label=model_name[idz])\n",
    "        if (idx == 0) & (idy == 0):\n",
    "            ax.legend()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms = ['c0','c1','c2','c3']\n",
    "masks = [where_elnino_onset,\n",
    "         where_lanina_onset]\n",
    "models = [cola_nino34, aer04_nino34, florA_nino34, florB_nino34, cm3_nino34, cm4_nino34]\n",
    "model_name = ['cola','aer04','florA','florB','cm3','cm4']\n",
    "\n",
    "fig = plt.figure(figsize=(5*len(anoms),3*len(masks)))\n",
    "axes = fig.subplots(nrows=len(masks), ncols=len(anoms), sharex=True)\n",
    "for idx, anom in enumerate(anoms):\n",
    "    for idy, mask in enumerate(masks):\n",
    "        if len(anoms) == 1:\n",
    "            ax = axes[idy]\n",
    "        elif len(masks) == 1:\n",
    "            ax = axes[idx]\n",
    "        else:\n",
    "            ax = axes[idy, idx]\n",
    "        for idz, model in enumerate(models):\n",
    "            sign_test = doppyo.skill.sign_test(regr_nino34[anom].where(mask[anom]), \n",
    "                                               model[anom].mean('ensemble').where(mask[anom]), \n",
    "                                               obs_2_use[anom].sel(init_date=slice('1999','2015')).where(mask[anom]))\n",
    "            \n",
    "            sign_masked = sign_test[0].where(mask[anom]).fillna(0)\n",
    "            conf_masked = sign_test[1].where(mask[anom]).fillna(0)\n",
    "            sign_area = doppyo.utils.integrate(sign_masked, over_dim='init_date', \n",
    "                                               x=(1+0*sign_masked.init_date.astype(int)).cumsum('init_date'), method='rect')\n",
    "            conf_area = doppyo.utils.integrate(conf_masked, over_dim='init_date', \n",
    "                                               x=(1+0*conf_masked.init_date.astype(int)).cumsum('init_date'), method='rect')\n",
    "            \n",
    "            if idz == 0:\n",
    "                ax.fill_between(conf_area.lead_time,\n",
    "                                -1 * conf_area, conf_area, color='gray', alpha=0.2, label='_nolegend_')\n",
    "            ax.plot(sign_area.lead_time, sign_area, label=model_name[idz])\n",
    "        if (idx == 0) & (idy == 0):\n",
    "            ax.legend()\n",
    "        \n",
    "        # Adjust y-axes limits to be symmetric -----\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        ylim = max([abs(ymin), abs(ymax)])\n",
    "        ax.set_ylim(-ylim, ylim)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above skill scores are conditioned on the actual occurence of ENSO events, and, as such, assess the tendency of the forecasts to provide false negatives. In the following, model forecasts are used to determine whether or not an event occurred. **This assesses the tendency of the forecasts to provide false positives.** As we shall see, these results prove very difficult to interpret because each model uses a very different subset of data in its assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get forecast El Ninos and La Ninas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_elnino_onset_cola = where_elnino_cola.apply(where_condition_events, method='onset')\n",
    "where_lanina_onset_cola = where_lanina_cola.apply(where_condition_events, method='onset')\n",
    "\n",
    "where_elnino_onset_aer04 = where_elnino_aer04.apply(where_condition_events, method='onset')\n",
    "where_lanina_onset_aer04 = where_lanina_aer04.apply(where_condition_events, method='onset')\n",
    "\n",
    "where_elnino_onset_florA = where_elnino_florA.apply(where_condition_events, method='onset')\n",
    "where_lanina_onset_florA = where_lanina_florA.apply(where_condition_events, method='onset')\n",
    "\n",
    "where_elnino_onset_florB = where_elnino_florB.apply(where_condition_events, method='onset')\n",
    "where_lanina_onset_florB = where_lanina_florB.apply(where_condition_events, method='onset')\n",
    "\n",
    "where_elnino_onset_cm3 = where_elnino_cm3.apply(where_condition_events, method='onset')\n",
    "where_lanina_onset_cm3 = where_lanina_cm3.apply(where_condition_events, method='onset')\n",
    "\n",
    "where_elnino_onset_cm4 = where_elnino_cm4.apply(where_condition_events, method='onset')\n",
    "where_lanina_onset_cm4 = where_lanina_cm4.apply(where_condition_events, method='onset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead = 8\n",
    "anoms = ['c0','c1','c2']\n",
    "mask_strs = ['where_elnino_onset',\n",
    "             'where_lanina_onset']\n",
    "models = [cola_nino34, aer04_nino34, florA_nino34, florB_nino34, cm3_nino34, cm4_nino34]\n",
    "model_names = ['cola','aer04','florA','florB','cm3','cm4']\n",
    "\n",
    "fig = plt.figure(figsize=(5*len(anoms),3*len(masks)))\n",
    "axes = fig.subplots(nrows=len(mask_strs), ncols=len(anoms), sharex=True)\n",
    "for idx, anom in enumerate(anoms):\n",
    "    for idy, mask_str in enumerate(mask_strs):\n",
    "        if len(anoms) == 1:\n",
    "            ax = axes[idy]\n",
    "        elif len(masks) == 1:\n",
    "            ax = axes[idx]\n",
    "        else:\n",
    "            ax = axes[idy, idx]\n",
    "        for idz, model in enumerate(models):\n",
    "            to_exec = 'mask = ' + mask_str + '_' + model_names[idz]\n",
    "            exec(to_exec)\n",
    "            sign, conf = doppyo.skill.sign_test(regr_nino34[anom].where(mask[anom]), \n",
    "                                               model[anom].mean('ensemble').where(mask[anom]), \n",
    "                                               obs_2_use[anom].sel(init_date=slice('1999','2015')).where(mask[anom]))\n",
    "            #if idz == 0:\n",
    "            ax.fill_between(conf.init_date.values,\n",
    "                            -1 * conf.sel(lead_time=lead), \n",
    "                            conf.sel(lead_time=lead), alpha=0.2, label='_nolegend_')\n",
    "            ax.plot(sign.init_date, sign.sel(lead_time=lead), label=model_names[idz])\n",
    "        if (idx == 0) & (idy == 0):\n",
    "            ax.legend()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms = ['c0','c1','c2']\n",
    "mask_strs = ['where_elnino_onset',\n",
    "             'where_lanina_onset']\n",
    "models = [cola_nino34, aer04_nino34, florA_nino34, florB_nino34, cm3_nino34, cm4_nino34]\n",
    "model_names = ['cola','aer04','florA','florB','cm3','cm4']\n",
    "\n",
    "fig = plt.figure(figsize=(5*len(anoms),3*len(masks)))\n",
    "axes = fig.subplots(nrows=len(masks), ncols=len(anoms), sharex=True)\n",
    "for idx, anom in enumerate(anoms):\n",
    "    for idy, mask_str in enumerate(mask_strs):\n",
    "        if len(anoms) == 1:\n",
    "            ax = axes[idy]\n",
    "        elif len(masks) == 1:\n",
    "            ax = axes[idx]\n",
    "        else:\n",
    "            ax = axes[idy, idx]\n",
    "        for idz, model in enumerate(models):\n",
    "            to_exec = 'mask = ' + mask_str + '_' + model_names[idz]\n",
    "            exec(to_exec)\n",
    "            \n",
    "            sign_test = doppyo.skill.sign_test(regr_nino34[anom].where(mask[anom]), \n",
    "                                               model[anom].mean('ensemble').where(mask[anom]), \n",
    "                                               obs_2_use[anom].sel(init_date=slice('1999','2015')).where(mask[anom]))\n",
    "            \n",
    "            sign_masked = sign_test[0].where(mask[anom]).fillna(0)\n",
    "            conf_masked = sign_test[1].where(mask[anom]).fillna(0)\n",
    "            sign_area = doppyo.utils.integrate(sign_masked, over_dim='init_date', \n",
    "                                               x=(1+0*sign_masked.init_date.astype(int)).cumsum('init_date'), method='rect')\n",
    "            conf_area = doppyo.utils.integrate(conf_masked, over_dim='init_date', \n",
    "                                               x=(1+0*conf_masked.init_date.astype(int)).cumsum('init_date'), method='rect')\n",
    "            \n",
    "            # if idz == 0:\n",
    "            ax.fill_between(conf_area.lead_time,\n",
    "                            -1 * conf_area, conf_area, alpha=0.2, label='_nolegend_')\n",
    "            ax.plot(sign_area.lead_time, sign_area, label=model_name[idz])\n",
    "        if (idx == 0) & (idy == 0):\n",
    "            ax.legend()\n",
    "        \n",
    "        # Adjust y-axes limits to be symmetric -----\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        ylim = max([abs(ymin), abs(ymax)])\n",
    "        ax.set_ylim(-ylim, ylim)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about **decay** of El Nino and La Nina?\n",
    "Here we assess, for each of El Nino and La Nina, forecasts which end **outside of** an event, but are started in an event\n",
    "\n",
    "Observations are used to determine whether or not an event occurred. **This assesses the tendency of the forecasts to provide false negatives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_elnino_decay = where_elnino.apply(where_condition_events, method='decay')\n",
    "where_lanina_decay = where_lanina.apply(where_condition_events, method='decay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead = 6\n",
    "anoms = ['c0','c1','c2','c3']\n",
    "masks = [where_elnino_decay,\n",
    "         where_lanina_decay]\n",
    "models = [cola_nino34, aer04_nino34, florA_nino34, florB_nino34, cm3_nino34, cm4_nino34]\n",
    "model_name = ['cola','aer04','florA','florB','cm3','cm4']\n",
    "\n",
    "fig = plt.figure(figsize=(5*len(anoms),3*len(masks)))\n",
    "axes = fig.subplots(nrows=len(masks), ncols=len(anoms), sharex=True)\n",
    "for idx, anom in enumerate(anoms):\n",
    "    for idy, mask in enumerate(masks):\n",
    "        if len(anoms) == 1:\n",
    "            ax = axes[idy]\n",
    "        elif len(masks) == 1:\n",
    "            ax = axes[idx]\n",
    "        else:\n",
    "            ax = axes[idy, idx]\n",
    "        for idz, model in enumerate(models):\n",
    "            sign, conf = doppyo.skill.sign_test(regr_nino34[anom].where(mask[anom]), \n",
    "                                               model[anom].mean('ensemble').where(mask[anom]), \n",
    "                                               obs_2_use[anom].sel(init_date=slice('1999','2015')).where(mask[anom]))\n",
    "            if idz == 0:\n",
    "                ax.fill_between(conf.init_date.values,\n",
    "                                -1 * conf.sel(lead_time=lead), \n",
    "                                conf.sel(lead_time=lead), color='gray', alpha=0.2, label='_nolegend_')\n",
    "            ax.plot(sign.init_date, sign.sel(lead_time=lead), label=model_name[idz])\n",
    "        if (idx == 0) & (idy == 0):\n",
    "            ax.legend()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms = ['c0','c1','c2','c3']\n",
    "masks = [where_elnino_decay,\n",
    "         where_lanina_decay]\n",
    "models = [cola_nino34, aer04_nino34, florA_nino34, florB_nino34, cm3_nino34, cm4_nino34]\n",
    "model_name = ['cola','aer04','florA','florB','cm3','cm4']\n",
    "\n",
    "fig = plt.figure(figsize=(5*len(anoms),3*len(masks)))\n",
    "axes = fig.subplots(nrows=len(masks), ncols=len(anoms), sharex=True)\n",
    "for idx, anom in enumerate(anoms):\n",
    "    for idy, mask in enumerate(masks):\n",
    "        if len(anoms) == 1:\n",
    "            ax = axes[idy]\n",
    "        elif len(masks) == 1:\n",
    "            ax = axes[idx]\n",
    "        else:\n",
    "            ax = axes[idy, idx]\n",
    "        for idz, model in enumerate(models):\n",
    "            sign_test = doppyo.skill.sign_test(regr_nino34[anom].where(mask[anom]), \n",
    "                                               model[anom].mean('ensemble').where(mask[anom]), \n",
    "                                               obs_2_use[anom].sel(init_date=slice('1999','2015')).where(mask[anom]))\n",
    "            \n",
    "            sign_masked = sign_test[0].where(mask[anom]).fillna(0)\n",
    "            conf_masked = sign_test[1].where(mask[anom]).fillna(0)\n",
    "            sign_area = doppyo.utils.integrate(sign_masked, over_dim='init_date', \n",
    "                                               x=(1+0*sign_masked.init_date.astype(int)).cumsum('init_date'), method='rect')\n",
    "            conf_area = doppyo.utils.integrate(conf_masked, over_dim='init_date', \n",
    "                                               x=(1+0*conf_masked.init_date.astype(int)).cumsum('init_date'), method='rect')\n",
    "            \n",
    "            if idz == 0:\n",
    "                ax.fill_between(conf_area.lead_time,\n",
    "                                -1 * conf_area, conf_area, color='gray', alpha=0.2, label='_nolegend_')\n",
    "            ax.plot(sign_area.lead_time, sign_area, label=model_name[idz])\n",
    "        if (idx == 0) & (idy == 0):\n",
    "            ax.legend()\n",
    "        \n",
    "        # Adjust y-axes limits to be symmetric -----\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        ylim = max([abs(ymin), abs(ymax)])\n",
    "        ax.set_ylim(-ylim, ylim)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about specifically decay **from** El Nino **to** La Nina?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead = 10\n",
    "anoms = ['c0','c1','c2']\n",
    "masks = [where_elnino_decay & where_lanina.where(where_lanina == 0, other=1)]\n",
    "models = [cola_nino34, aer04_nino34, florA_nino34, florB_nino34, cm3_nino34, cm4_nino34]\n",
    "model_name = ['cola','aer04','florA','florB','cm3','cm4']\n",
    "\n",
    "fig = plt.figure(figsize=(5*len(anoms),3*len(masks)))\n",
    "axes = fig.subplots(nrows=len(masks), ncols=len(anoms), sharex=True)\n",
    "for idx, anom in enumerate(anoms):\n",
    "    for idy, mask in enumerate(masks):\n",
    "        if len(anoms) == 1:\n",
    "            ax = axes[idy]\n",
    "        elif len(masks) == 1:\n",
    "            ax = axes[idx]\n",
    "        else:\n",
    "            ax = axes[idx, idy]\n",
    "        for idz, model in enumerate(models):\n",
    "            sign_test = doppyo.skill.sign_test(regr_nino34[anom].where(mask[anom]), \n",
    "                                               model[anom].mean('ensemble').where(mask[anom]), \n",
    "                                               obs_2_use[anom].sel(init_date=slice('1999','2015')).where(mask[anom]))\n",
    "            if idz == 0:\n",
    "                ax.fill_between(sign_test[1].init_date.values,\n",
    "                                -1 * sign_test[1].sel(lead_time=lead), \n",
    "                                sign_test[1].sel(lead_time=lead), color='gray', alpha=0.2, label='_nolegend_')\n",
    "            ax.plot(sign_test[0].init_date, sign_test[0].sel(lead_time=lead), label=model_name[idz])\n",
    "        if (idx == 0) & (idy == 0):\n",
    "            ax.legend()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms = ['c0','c1','c2']\n",
    "masks = [where_elnino_decay & where_lanina.where(where_lanina == 0, other=1)]\n",
    "models = [cola_nino34, aer04_nino34, florA_nino34, florB_nino34, cm3_nino34, cm4_nino34]\n",
    "model_name = ['cola','aer04','florA','florB','cm3','cm4']\n",
    "\n",
    "fig = plt.figure(figsize=(5*len(anoms),3*len(masks)))\n",
    "axes = fig.subplots(nrows=len(masks), ncols=len(anoms), sharex=True)\n",
    "for idx, anom in enumerate(anoms):\n",
    "    for idy, mask in enumerate(masks):\n",
    "        if len(anoms) == 1:\n",
    "            ax = axes[idy]\n",
    "        elif len(masks) == 1:\n",
    "            ax = axes[idx]\n",
    "        else:\n",
    "            ax = axes[idx, idy]\n",
    "        for idz, model in enumerate(models):\n",
    "            sign_test = doppyo.skill.sign_test(regr_nino34[anom].where(mask[anom]), \n",
    "                                               model[anom].mean('ensemble').where(mask[anom]), \n",
    "                                               obs_2_use[anom].sel(init_date=slice('1999','2015')).where(mask[anom]))\n",
    "            \n",
    "            sign_area = doppyo.utils.integrate(sign_test[0], over_dim='init_date', \n",
    "                                               x=(1+0*sign_test[0].init_date.astype(int)).cumsum('init_date'))\n",
    "            conf_area = doppyo.utils.integrate(sign_test[1], over_dim='init_date', \n",
    "                                               x=(1+0*sign_test[1].init_date.astype(int)).cumsum('init_date'))\n",
    "            \n",
    "            if idz == 0:\n",
    "                ax.fill_between(conf_area.lead_time,\n",
    "                                -1 * conf_area, conf_area, color='gray', alpha=0.2, label='_nolegend_')\n",
    "            ax.plot(sign_area.lead_time, sign_area, label=model_name[idz])\n",
    "        if (idx == 0) & (idy == 0):\n",
    "            ax.legend()\n",
    "        \n",
    "        # Adjust y-axes limits to be symmetric -----\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        ylim = max([abs(ymin), abs(ymax)])\n",
    "        ax.set_ylim(-ylim, ylim)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do the results compare for c1 computed over the full 1982 -> 2015 period?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead = 3\n",
    "anoms = ['c1','c1full']\n",
    "masks = [1 + 0*where_elnino]\n",
    "models = [cola_nino34, aer04_nino34, florA_nino34, florB_nino34, cm3_nino34, cm4_nino34]\n",
    "model_name = ['cola','aer04','florA','florB','cm3','cm4']\n",
    "\n",
    "fig = plt.figure(figsize=(5*len(anoms),3*len(masks)))\n",
    "axes = fig.subplots(nrows=len(masks), ncols=len(anoms), sharex=True)\n",
    "for idx, anom in enumerate(anoms):\n",
    "    for idy, mask in enumerate(masks):\n",
    "        if len(anoms) == 1:\n",
    "            ax = axes[idy]\n",
    "        elif len(masks) == 1:\n",
    "            ax = axes[idx]\n",
    "        else:\n",
    "            ax = axes[idy, idx]\n",
    "        for idz, model in enumerate(models):\n",
    "            sign, conf = doppyo.skill.sign_test(regr_nino34[anom].where(mask[anom]), \n",
    "                                               model[anom].mean('ensemble').where(mask[anom]), \n",
    "                                               obs_2_use[anom].sel(init_date=slice('1999','2015')).where(mask[anom]))\n",
    "            if idz == 0:\n",
    "                ax.fill_between(conf.init_date.values,\n",
    "                                -1 * conf.sel(lead_time=lead), \n",
    "                                conf.sel(lead_time=lead), color='gray', alpha=0.2, label='_nolegend_')\n",
    "            ax.plot(sign.init_date, sign.sel(lead_time=lead), label=model_name[idz])\n",
    "        if (idx == 0) & (idy == 0):\n",
    "            ax.legend()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms = ['c1','c1full']\n",
    "masks = [1 + 0*where_elnino]\n",
    "models = [cola_nino34, aer04_nino34, florA_nino34, florB_nino34, cm3_nino34, cm4_nino34]\n",
    "model_name = ['cola','aer04','florA','florB','cm3','cm4']\n",
    "\n",
    "fig = plt.figure(figsize=(5*len(anoms),3*len(masks)))\n",
    "axes = fig.subplots(nrows=len(masks), ncols=len(anoms), sharex=True)\n",
    "for idx, anom in enumerate(anoms):\n",
    "    for idy, mask in enumerate(masks):\n",
    "        if len(anoms) == 1:\n",
    "            ax = axes[idy]\n",
    "        elif len(masks) == 1:\n",
    "            ax = axes[idx]\n",
    "        else:\n",
    "            ax = axes[idy, idx]\n",
    "        for idz, model in enumerate(models):\n",
    "            sign_test = doppyo.skill.sign_test(regr_nino34[anom].where(mask[anom]), \n",
    "                                               model[anom].mean('ensemble').where(mask[anom]), \n",
    "                                               obs_2_use[anom].sel(init_date=slice('1999','2015')).where(mask[anom]))\n",
    "            \n",
    "            sign_masked = sign_test[0].where(mask[anom], drop=True)\n",
    "            conf_masked = sign_test[1].where(mask[anom], drop=True)\n",
    "            sign_area = doppyo.utils.integrate(sign_masked, over_dim='init_date', \n",
    "                                               x=(1+0*sign_masked.init_date.astype(int)).cumsum('init_date'), method='rect')\n",
    "            conf_area = doppyo.utils.integrate(conf_masked, over_dim='init_date', \n",
    "                                               x=(1+0*conf_masked.init_date.astype(int)).cumsum('init_date'), method='rect')\n",
    "            \n",
    "            if idz == 0:\n",
    "                ax.fill_between(conf_area.lead_time,\n",
    "                                -1 * conf_area, conf_area, color='gray', alpha=0.2, label='_nolegend_')\n",
    "            ax.plot(sign_area.lead_time, sign_area, label=model_name[idz])\n",
    "        if (idx == 0) & (idy == 0):\n",
    "            ax.legend()\n",
    "        \n",
    "        # Adjust y-axes limits to be symmetric -----\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        ylim = max([abs(ymin), abs(ymax)])\n",
    "        ax.set_ylim(-ylim, ylim)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
